{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crytosystem Identifier Using Back Propagation Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import keras\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Reading Data from a Text File\n",
    "def read_text_file(fname):\n",
    "    with open(fname,'r') as f:\n",
    "        text=f.readlines()\n",
    "    for i in range(len(text)):\n",
    "        text[i]=text[i].rstrip(\"\\n\")\n",
    "    return text\n",
    "\n",
    "#Function for Converting the text array into its respective ASCII value.\n",
    "def txt_char(arr,size=200):\n",
    "    a=len(arr)\n",
    "    res=32*np.ones((a,size))\n",
    "    for i in range(a):\n",
    "        arr[i]+=\" \"\n",
    "        for j in range(size):\n",
    "            res[i,j]=ord(arr[i][j])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have Extracted frequency features from the Data.\n",
    "def extract_features(arr,f=7):\n",
    "    res=[]\n",
    "    for i in arr:\n",
    "        a=Counter(i)\n",
    "        r=list(a.values())\n",
    "        s=np.sort(r)\n",
    "        res.append([np.mean(s[:f]),np.mean(s[-1*f:])])\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_features,train_labels,valid_features,valid_labels,hid_1,input_dim=2,epochs=50,verb=2):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = hid_1, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "    classifier.fit(train_features, train_labels, batch_size = 10, epochs = 50, validation_data=(valid_features,valid_labels),verbose=verb)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading of Training Data\n",
    "sub_data=read_text_file(os.path.join('Dataset','sub_train.txt')) \n",
    "vig_data=read_text_file(os.path.join('Dataset','vig_train.txt')) \n",
    "\n",
    "shuffle(sub_data)\n",
    "shuffle(vig_data)\n",
    "\n",
    "sub_train,sub_val=sub_data[:40],sub_data[40:]\n",
    "vig_train,vig_val=vig_data[:40],vig_data[40:]\n",
    "\n",
    "#Reading of Testing Data\n",
    "sub_test=read_text_file(os.path.join('Dataset','sub_test.txt'))\n",
    "vig_test=read_text_file(os.path.join('Dataset','vig_test.txt'))\n",
    "\n",
    "sen_train=np.asarray(sub_train+vig_train)\n",
    "sen_valid=np.asarray(sub_val+vig_val)\n",
    "sen_test=np.asarray(sub_test+vig_test)\n",
    "\n",
    "train_data=txt_char(sen_train)\n",
    "valid_data=txt_char(sen_valid)\n",
    "test_data=txt_char(sen_test)\n",
    "\n",
    "train_labels=np.asarray([0]*len(sub_train)+[1]*len(vig_train))\n",
    "valid_labels=np.asarray([0]*len(sub_val)+[1]*len(vig_val))\n",
    "test_labels=np.asarray([0]*len(sub_test)+[1]*len(vig_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.6925 - acc: 0.5125 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6923 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6915 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 371us/step - loss: 0.6914 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6907 - acc: 0.5000 - val_loss: 0.6906 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6906 - acc: 0.5000 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6905 - acc: 0.5000 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 451us/step - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 438us/step - loss: 0.6895 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.6892 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.6889 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 489us/step - loss: 0.6886 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6883 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 378us/step - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6879 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6877 - acc: 0.5000 - val_loss: 0.6876 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 473us/step - loss: 0.6875 - acc: 0.5000 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6870 - acc: 0.5000 - val_loss: 0.6870 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 385us/step - loss: 0.6867 - acc: 0.5000 - val_loss: 0.6866 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6863 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6858 - acc: 0.5000 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6854 - acc: 0.5000 - val_loss: 0.6857 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 464us/step - loss: 0.6849 - acc: 0.5000 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.6845 - acc: 0.5000 - val_loss: 0.6847 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 539us/step - loss: 0.6839 - acc: 0.5000 - val_loss: 0.6842 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6834 - acc: 0.5000 - val_loss: 0.6838 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.6827 - acc: 0.5000 - val_loss: 0.6834 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 463us/step - loss: 0.6820 - acc: 0.5000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6812 - acc: 0.5000 - val_loss: 0.6823 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6811 - acc: 0.5000 - val_loss: 0.6817 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6798 - acc: 0.5000 - val_loss: 0.6810 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6789 - acc: 0.5000 - val_loss: 0.6805 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6777 - acc: 0.5000 - val_loss: 0.6798 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 345us/step - loss: 0.6769 - acc: 0.5000 - val_loss: 0.6791 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6762 - acc: 0.5000 - val_loss: 0.6783 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6746 - acc: 0.5000 - val_loss: 0.6776 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6735 - acc: 0.5000 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6724 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 368us/step - loss: 0.6707 - acc: 0.5000 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6698 - acc: 0.5000 - val_loss: 0.6740 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6680 - acc: 0.5250 - val_loss: 0.6731 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6665 - acc: 0.5500 - val_loss: 0.6721 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6649 - acc: 0.5500 - val_loss: 0.6710 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6632 - acc: 0.5500 - val_loss: 0.6699 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.6616 - acc: 0.5500 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6596 - acc: 0.5625 - val_loss: 0.6675 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6576 - acc: 0.6000 - val_loss: 0.6662 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6556 - acc: 0.5875 - val_loss: 0.6649 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6540 - acc: 0.6000 - val_loss: 0.6635 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6518 - acc: 0.6125 - val_loss: 0.6621 - val_acc: 0.5500\n",
      "5 0.65\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.6941 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.4875 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6928 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6927 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6923 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6920 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 363us/step - loss: 0.6918 - acc: 0.5000 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6914 - acc: 0.5000 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6912 - acc: 0.5000 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6907 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6903 - acc: 0.5000 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6894 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6893 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6882 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6879 - acc: 0.5000 - val_loss: 0.6873 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6868 - acc: 0.5000 - val_loss: 0.6868 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6862 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6854 - acc: 0.5000 - val_loss: 0.6857 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6847 - acc: 0.5000 - val_loss: 0.6851 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6843 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6831 - acc: 0.5000 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6821 - acc: 0.5000 - val_loss: 0.6831 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6813 - acc: 0.5000 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.6798 - acc: 0.5000 - val_loss: 0.6815 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6788 - acc: 0.5000 - val_loss: 0.6806 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6777 - acc: 0.5000 - val_loss: 0.6799 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6764 - acc: 0.5000 - val_loss: 0.6789 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6748 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 391us/step - loss: 0.6739 - acc: 0.5125 - val_loss: 0.6772 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6721 - acc: 0.5250 - val_loss: 0.6761 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6719 - acc: 0.5250 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6689 - acc: 0.5125 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6681 - acc: 0.5500 - val_loss: 0.6729 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6656 - acc: 0.5500 - val_loss: 0.6719 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 344us/step - loss: 0.6642 - acc: 0.5500 - val_loss: 0.6707 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6623 - acc: 0.5500 - val_loss: 0.6695 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.6604 - acc: 0.5625 - val_loss: 0.6683 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6587 - acc: 0.6250 - val_loss: 0.6670 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.6569 - acc: 0.6250 - val_loss: 0.6658 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6547 - acc: 0.6375 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6537 - acc: 0.6250 - val_loss: 0.6631 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6518 - acc: 0.6875 - val_loss: 0.6619 - val_acc: 0.6000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6486 - acc: 0.7125 - val_loss: 0.6604 - val_acc: 0.6000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6466 - acc: 0.6875 - val_loss: 0.6589 - val_acc: 0.5500\n",
      "10 0.65\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.6905 - acc: 0.5000 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6899 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.6893 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.6888 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.6883 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6878 - acc: 0.5000 - val_loss: 0.6871 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6869 - acc: 0.5000 - val_loss: 0.6862 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6865 - acc: 0.5000 - val_loss: 0.6858 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6858 - acc: 0.5000 - val_loss: 0.6853 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6854 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 347us/step - loss: 0.6850 - acc: 0.5000 - val_loss: 0.6845 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6840 - acc: 0.5000 - val_loss: 0.6839 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6833 - acc: 0.5000 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6824 - acc: 0.5000 - val_loss: 0.6828 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6815 - acc: 0.5000 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6815 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6795 - acc: 0.5000 - val_loss: 0.6807 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6788 - acc: 0.5000 - val_loss: 0.6798 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6771 - acc: 0.5000 - val_loss: 0.6789 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6756 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6741 - acc: 0.5000 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 301us/step - loss: 0.6726 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6710 - acc: 0.5000 - val_loss: 0.6748 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6690 - acc: 0.5250 - val_loss: 0.6734 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6671 - acc: 0.5125 - val_loss: 0.6721 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6649 - acc: 0.5250 - val_loss: 0.6706 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6627 - acc: 0.5375 - val_loss: 0.6690 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6604 - acc: 0.5500 - val_loss: 0.6674 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 689us/step - loss: 0.6580 - acc: 0.5500 - val_loss: 0.6658 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 393us/step - loss: 0.6550 - acc: 0.5750 - val_loss: 0.6640 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6523 - acc: 0.6250 - val_loss: 0.6622 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6502 - acc: 0.6000 - val_loss: 0.6603 - val_acc: 0.5500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.6465 - acc: 0.6750 - val_loss: 0.6584 - val_acc: 0.5500\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.6442 - acc: 0.7000 - val_loss: 0.6564 - val_acc: 0.6000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6441 - acc: 0.6750 - val_loss: 0.6548 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6385 - acc: 0.7000 - val_loss: 0.6524 - val_acc: 0.6000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 322us/step - loss: 0.6344 - acc: 0.7125 - val_loss: 0.6502 - val_acc: 0.6000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 321us/step - loss: 0.6307 - acc: 0.7125 - val_loss: 0.6480 - val_acc: 0.6000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6281 - acc: 0.7125 - val_loss: 0.6461 - val_acc: 0.6000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6242 - acc: 0.7125 - val_loss: 0.6434 - val_acc: 0.6000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6210 - acc: 0.7125 - val_loss: 0.6409 - val_acc: 0.6500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6172 - acc: 0.7250 - val_loss: 0.6387 - val_acc: 0.6000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6146 - acc: 0.7125 - val_loss: 0.6367 - val_acc: 0.6000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6089 - acc: 0.7125 - val_loss: 0.6338 - val_acc: 0.6000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6052 - acc: 0.7750 - val_loss: 0.6308 - val_acc: 0.7000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 322us/step - loss: 0.6011 - acc: 0.7875 - val_loss: 0.6281 - val_acc: 0.7000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5977 - acc: 0.7750 - val_loss: 0.6258 - val_acc: 0.7000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.5954 - acc: 0.7250 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5900 - acc: 0.7500 - val_loss: 0.6199 - val_acc: 0.7000\n",
      "15 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.6927 - acc: 0.4750 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.6914 - acc: 0.5000 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6901 - acc: 0.5000 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6875 - acc: 0.5000 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6871 - acc: 0.5000 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6868 - acc: 0.5000 - val_loss: 0.6857 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6851 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6846 - acc: 0.5000 - val_loss: 0.6846 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6839 - acc: 0.5000 - val_loss: 0.6841 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6831 - acc: 0.5000 - val_loss: 0.6835 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 413us/step - loss: 0.6819 - acc: 0.5000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6812 - acc: 0.5000 - val_loss: 0.6821 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6805 - acc: 0.5000 - val_loss: 0.6813 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6795 - acc: 0.5000 - val_loss: 0.6807 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6777 - acc: 0.5000 - val_loss: 0.6797 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6767 - acc: 0.5000 - val_loss: 0.6788 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6750 - acc: 0.5000 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6737 - acc: 0.5000 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6730 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 335us/step - loss: 0.6702 - acc: 0.5000 - val_loss: 0.6747 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6687 - acc: 0.5250 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6671 - acc: 0.5125 - val_loss: 0.6722 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6645 - acc: 0.5375 - val_loss: 0.6709 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6624 - acc: 0.5500 - val_loss: 0.6694 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6602 - acc: 0.5500 - val_loss: 0.6679 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 332us/step - loss: 0.6576 - acc: 0.5500 - val_loss: 0.6662 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6567 - acc: 0.5625 - val_loss: 0.6647 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.6534 - acc: 0.5750 - val_loss: 0.6627 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6497 - acc: 0.6625 - val_loss: 0.6609 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6468 - acc: 0.6625 - val_loss: 0.6592 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6452 - acc: 0.6125 - val_loss: 0.6573 - val_acc: 0.5000\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 338us/step - loss: 0.6412 - acc: 0.6375 - val_loss: 0.6553 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6373 - acc: 0.6875 - val_loss: 0.6530 - val_acc: 0.5500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6364 - acc: 0.7000 - val_loss: 0.6505 - val_acc: 0.6000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6312 - acc: 0.7125 - val_loss: 0.6482 - val_acc: 0.6000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6280 - acc: 0.7125 - val_loss: 0.6464 - val_acc: 0.6000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6241 - acc: 0.7000 - val_loss: 0.6444 - val_acc: 0.6000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6229 - acc: 0.7000 - val_loss: 0.6428 - val_acc: 0.5500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6212 - acc: 0.7625 - val_loss: 0.6386 - val_acc: 0.6500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6136 - acc: 0.7250 - val_loss: 0.6365 - val_acc: 0.6000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6100 - acc: 0.7250 - val_loss: 0.6339 - val_acc: 0.6000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6058 - acc: 0.7250 - val_loss: 0.6318 - val_acc: 0.6000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6029 - acc: 0.7000 - val_loss: 0.6299 - val_acc: 0.6000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5997 - acc: 0.7625 - val_loss: 0.6263 - val_acc: 0.7000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5963 - acc: 0.7625 - val_loss: 0.6257 - val_acc: 0.6000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5959 - acc: 0.7375 - val_loss: 0.6207 - val_acc: 0.7000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.5870 - acc: 0.8000 - val_loss: 0.6182 - val_acc: 0.7000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.5843 - acc: 0.8000 - val_loss: 0.6159 - val_acc: 0.7000\n",
      "20 0.8\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.6947 - acc: 0.4375 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 418us/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6924 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.6914 - acc: 0.5000 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6907 - acc: 0.5000 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.6902 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6816 - acc: 0.600 - 0s 564us/step - loss: 0.6892 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 501us/step - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6876 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 428us/step - loss: 0.6883 - acc: 0.5000 - val_loss: 0.6868 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 419us/step - loss: 0.6866 - acc: 0.5000 - val_loss: 0.6864 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6860 - acc: 0.5000 - val_loss: 0.6856 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6850 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6844 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6829 - acc: 0.5000 - val_loss: 0.6836 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6818 - acc: 0.5000 - val_loss: 0.6827 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 305us/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6795 - acc: 0.5000 - val_loss: 0.6809 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6780 - acc: 0.5000 - val_loss: 0.6800 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6765 - acc: 0.5000 - val_loss: 0.6790 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 322us/step - loss: 0.6752 - acc: 0.5000 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6734 - acc: 0.5000 - val_loss: 0.6767 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6720 - acc: 0.5000 - val_loss: 0.6755 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6694 - acc: 0.5000 - val_loss: 0.6743 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6677 - acc: 0.5125 - val_loss: 0.6729 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6652 - acc: 0.5375 - val_loss: 0.6716 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.6631 - acc: 0.5500 - val_loss: 0.6701 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6607 - acc: 0.5625 - val_loss: 0.6684 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6583 - acc: 0.5875 - val_loss: 0.6666 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6555 - acc: 0.6250 - val_loss: 0.6648 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 332us/step - loss: 0.6525 - acc: 0.6250 - val_loss: 0.6628 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6492 - acc: 0.6500 - val_loss: 0.6607 - val_acc: 0.5500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6464 - acc: 0.6625 - val_loss: 0.6585 - val_acc: 0.5500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6426 - acc: 0.6875 - val_loss: 0.6562 - val_acc: 0.5500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6385 - acc: 0.7000 - val_loss: 0.6538 - val_acc: 0.6000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6347 - acc: 0.7125 - val_loss: 0.6511 - val_acc: 0.6000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.6324 - acc: 0.7375 - val_loss: 0.6484 - val_acc: 0.6000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6268 - acc: 0.7250 - val_loss: 0.6457 - val_acc: 0.6000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6230 - acc: 0.7125 - val_loss: 0.6430 - val_acc: 0.6000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6174 - acc: 0.7125 - val_loss: 0.6395 - val_acc: 0.6000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6140 - acc: 0.7125 - val_loss: 0.6369 - val_acc: 0.6000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6094 - acc: 0.7250 - val_loss: 0.6328 - val_acc: 0.7000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6108 - acc: 0.7750 - val_loss: 0.6301 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.5994 - acc: 0.8000 - val_loss: 0.6272 - val_acc: 0.6500\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5939 - acc: 0.7375 - val_loss: 0.6253 - val_acc: 0.6000\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 326us/step - loss: 0.5901 - acc: 0.7125 - val_loss: 0.6222 - val_acc: 0.6000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5839 - acc: 0.7625 - val_loss: 0.6175 - val_acc: 0.7000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5792 - acc: 0.8125 - val_loss: 0.6136 - val_acc: 0.7000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5751 - acc: 0.8000 - val_loss: 0.6099 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5716 - acc: 0.7750 - val_loss: 0.6080 - val_acc: 0.7000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5660 - acc: 0.7875 - val_loss: 0.6051 - val_acc: 0.7000\n",
      "25 0.8\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.6919 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6899 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6886 - acc: 0.5000 - val_loss: 0.6874 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 343us/step - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6871 - acc: 0.5000 - val_loss: 0.6861 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6855 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6852 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 306us/step - loss: 0.6839 - acc: 0.5000 - val_loss: 0.6842 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6829 - acc: 0.5000 - val_loss: 0.6834 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6820 - acc: 0.5000 - val_loss: 0.6827 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6811 - acc: 0.5000 - val_loss: 0.6820 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6799 - acc: 0.5000 - val_loss: 0.6811 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6786 - acc: 0.5000 - val_loss: 0.6803 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6779 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6760 - acc: 0.5000 - val_loss: 0.6783 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 298us/step - loss: 0.6742 - acc: 0.5000 - val_loss: 0.6773 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6722 - acc: 0.5000 - val_loss: 0.6761 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6706 - acc: 0.5000 - val_loss: 0.6748 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.6688 - acc: 0.5250 - val_loss: 0.6735 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6668 - acc: 0.5250 - val_loss: 0.6720 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6641 - acc: 0.5500 - val_loss: 0.6705 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6619 - acc: 0.5500 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6591 - acc: 0.5875 - val_loss: 0.6670 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6562 - acc: 0.5875 - val_loss: 0.6651 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6543 - acc: 0.6750 - val_loss: 0.6633 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6510 - acc: 0.7125 - val_loss: 0.6610 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6465 - acc: 0.7000 - val_loss: 0.6586 - val_acc: 0.5500\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6431 - acc: 0.6875 - val_loss: 0.6562 - val_acc: 0.5500\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6388 - acc: 0.7000 - val_loss: 0.6535 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 322us/step - loss: 0.6345 - acc: 0.7125 - val_loss: 0.6507 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6304 - acc: 0.7125 - val_loss: 0.6477 - val_acc: 0.6000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6286 - acc: 0.7125 - val_loss: 0.6451 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6218 - acc: 0.7125 - val_loss: 0.6417 - val_acc: 0.6500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6182 - acc: 0.7250 - val_loss: 0.6389 - val_acc: 0.6000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6140 - acc: 0.7500 - val_loss: 0.6355 - val_acc: 0.7000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6093 - acc: 0.7625 - val_loss: 0.6333 - val_acc: 0.6000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6033 - acc: 0.7375 - val_loss: 0.6291 - val_acc: 0.7000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5972 - acc: 0.7750 - val_loss: 0.6259 - val_acc: 0.7000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5994 - acc: 0.7625 - val_loss: 0.6220 - val_acc: 0.8000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5875 - acc: 0.8125 - val_loss: 0.6193 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.5822 - acc: 0.7750 - val_loss: 0.6169 - val_acc: 0.6500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5778 - acc: 0.7875 - val_loss: 0.6125 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5723 - acc: 0.7875 - val_loss: 0.6084 - val_acc: 0.7000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5709 - acc: 0.7750 - val_loss: 0.6072 - val_acc: 0.7000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5599 - acc: 0.7875 - val_loss: 0.6007 - val_acc: 0.7500\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5563 - acc: 0.8125 - val_loss: 0.5973 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5541 - acc: 0.7750 - val_loss: 0.5929 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5467 - acc: 0.7875 - val_loss: 0.5897 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.5403 - acc: 0.8125 - val_loss: 0.5885 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.5410 - acc: 0.8125 - val_loss: 0.5902 - val_acc: 0.7000\n",
      "30 0.8\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.6960 - acc: 0.4875 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6923 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6906 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6896 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 301us/step - loss: 0.6874 - acc: 0.5000 - val_loss: 0.6864 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6858 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6850 - acc: 0.5000 - val_loss: 0.6850 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.6838 - acc: 0.5000 - val_loss: 0.6841 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6826 - acc: 0.5000 - val_loss: 0.6830 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6819 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6794 - acc: 0.5000 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6778 - acc: 0.5000 - val_loss: 0.6795 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6752 - acc: 0.5000 - val_loss: 0.6782 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6748 - acc: 0.5125 - val_loss: 0.6774 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6711 - acc: 0.5625 - val_loss: 0.6756 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6682 - acc: 0.5500 - val_loss: 0.6735 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6652 - acc: 0.5500 - val_loss: 0.6714 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6623 - acc: 0.5500 - val_loss: 0.6692 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6587 - acc: 0.5750 - val_loss: 0.6669 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6576 - acc: 0.7125 - val_loss: 0.6651 - val_acc: 0.6000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6514 - acc: 0.7125 - val_loss: 0.6621 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6464 - acc: 0.7125 - val_loss: 0.6592 - val_acc: 0.5500\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6429 - acc: 0.7000 - val_loss: 0.6565 - val_acc: 0.5500\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6423 - acc: 0.7250 - val_loss: 0.6538 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.6345 - acc: 0.7250 - val_loss: 0.6510 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6303 - acc: 0.7125 - val_loss: 0.6477 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6253 - acc: 0.7625 - val_loss: 0.6445 - val_acc: 0.7000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6205 - acc: 0.7625 - val_loss: 0.6411 - val_acc: 0.7000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6146 - acc: 0.7750 - val_loss: 0.6378 - val_acc: 0.6500\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6097 - acc: 0.7500 - val_loss: 0.6343 - val_acc: 0.6500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6081 - acc: 0.7125 - val_loss: 0.6321 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5988 - acc: 0.7875 - val_loss: 0.6274 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5944 - acc: 0.8000 - val_loss: 0.6238 - val_acc: 0.7500\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5900 - acc: 0.8000 - val_loss: 0.6202 - val_acc: 0.8000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.5852 - acc: 0.7750 - val_loss: 0.6167 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5798 - acc: 0.8000 - val_loss: 0.6144 - val_acc: 0.7000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5740 - acc: 0.7750 - val_loss: 0.6113 - val_acc: 0.7000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5678 - acc: 0.7750 - val_loss: 0.6059 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5638 - acc: 0.7750 - val_loss: 0.6020 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 329us/step - loss: 0.5577 - acc: 0.7750 - val_loss: 0.5982 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 302us/step - loss: 0.5541 - acc: 0.8000 - val_loss: 0.5961 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5472 - acc: 0.7875 - val_loss: 0.5917 - val_acc: 0.7500\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5450 - acc: 0.7875 - val_loss: 0.5870 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5445 - acc: 0.7875 - val_loss: 0.5890 - val_acc: 0.7000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5403 - acc: 0.8000 - val_loss: 0.5798 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5274 - acc: 0.7875 - val_loss: 0.5777 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5267 - acc: 0.7750 - val_loss: 0.5797 - val_acc: 0.7000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.5185 - acc: 0.7625 - val_loss: 0.5705 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 476us/step - loss: 0.5148 - acc: 0.7875 - val_loss: 0.5667 - val_acc: 0.8000\n",
      "35 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.6923 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6906 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6895 - acc: 0.5000 - val_loss: 0.6881 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6883 - acc: 0.5000 - val_loss: 0.6874 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6879 - acc: 0.5000 - val_loss: 0.6866 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6871 - acc: 0.5000 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6855 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6860 - acc: 0.5000 - val_loss: 0.6847 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6849 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6835 - acc: 0.5000 - val_loss: 0.6835 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6825 - acc: 0.5000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6814 - acc: 0.5000 - val_loss: 0.6820 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6801 - acc: 0.5000 - val_loss: 0.6813 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6789 - acc: 0.5000 - val_loss: 0.6802 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6770 - acc: 0.5000 - val_loss: 0.6792 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6758 - acc: 0.5000 - val_loss: 0.6781 - val_acc: 0.5000\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 326us/step - loss: 0.6739 - acc: 0.5000 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6725 - acc: 0.5000 - val_loss: 0.6757 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6702 - acc: 0.5250 - val_loss: 0.6745 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.6691 - acc: 0.5500 - val_loss: 0.6731 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6686 - acc: 0.5250 - val_loss: 0.6714 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6631 - acc: 0.5250 - val_loss: 0.6699 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6606 - acc: 0.5500 - val_loss: 0.6680 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6594 - acc: 0.6000 - val_loss: 0.6663 - val_acc: 0.5500\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6557 - acc: 0.6875 - val_loss: 0.6641 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6513 - acc: 0.6250 - val_loss: 0.6619 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6486 - acc: 0.6875 - val_loss: 0.6597 - val_acc: 0.5500\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6443 - acc: 0.6875 - val_loss: 0.6572 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6416 - acc: 0.7000 - val_loss: 0.6550 - val_acc: 0.5500\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 306us/step - loss: 0.6371 - acc: 0.7000 - val_loss: 0.6521 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6335 - acc: 0.7000 - val_loss: 0.6496 - val_acc: 0.6000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6279 - acc: 0.7125 - val_loss: 0.6465 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6240 - acc: 0.7125 - val_loss: 0.6434 - val_acc: 0.6000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6204 - acc: 0.7875 - val_loss: 0.6405 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6143 - acc: 0.7625 - val_loss: 0.6374 - val_acc: 0.6000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6099 - acc: 0.7125 - val_loss: 0.6346 - val_acc: 0.6000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6050 - acc: 0.7125 - val_loss: 0.6315 - val_acc: 0.6000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6029 - acc: 0.7875 - val_loss: 0.6269 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5943 - acc: 0.8125 - val_loss: 0.6233 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5899 - acc: 0.7875 - val_loss: 0.6208 - val_acc: 0.6500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5842 - acc: 0.8000 - val_loss: 0.6164 - val_acc: 0.7000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5782 - acc: 0.7750 - val_loss: 0.6130 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5727 - acc: 0.8000 - val_loss: 0.6082 - val_acc: 0.7500\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5670 - acc: 0.8000 - val_loss: 0.6047 - val_acc: 0.7500\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5607 - acc: 0.8000 - val_loss: 0.6026 - val_acc: 0.7000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5574 - acc: 0.7750 - val_loss: 0.5991 - val_acc: 0.7000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5520 - acc: 0.7875 - val_loss: 0.5921 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5468 - acc: 0.8000 - val_loss: 0.5891 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5401 - acc: 0.8000 - val_loss: 0.5857 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5341 - acc: 0.8000 - val_loss: 0.5833 - val_acc: 0.7500\n",
      "40 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.6942 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.7500\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6919 - acc: 0.5250 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6888 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6881 - acc: 0.5000 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6867 - acc: 0.5000 - val_loss: 0.6858 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6855 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6843 - acc: 0.5000 - val_loss: 0.6842 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6832 - acc: 0.5000 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6823 - acc: 0.5000 - val_loss: 0.6824 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6816 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 315us/step - loss: 0.6795 - acc: 0.5000 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6778 - acc: 0.5000 - val_loss: 0.6795 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6754 - acc: 0.5000 - val_loss: 0.6782 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6741 - acc: 0.5000 - val_loss: 0.6770 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6718 - acc: 0.5125 - val_loss: 0.6752 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6694 - acc: 0.5000 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.6662 - acc: 0.5250 - val_loss: 0.6719 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6656 - acc: 0.5875 - val_loss: 0.6705 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6609 - acc: 0.6125 - val_loss: 0.6683 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 316us/step - loss: 0.6579 - acc: 0.5750 - val_loss: 0.6662 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6543 - acc: 0.6250 - val_loss: 0.6640 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6518 - acc: 0.5875 - val_loss: 0.6617 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6475 - acc: 0.5875 - val_loss: 0.6593 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6434 - acc: 0.6875 - val_loss: 0.6565 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6431 - acc: 0.7500 - val_loss: 0.6547 - val_acc: 0.7000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6345 - acc: 0.7625 - val_loss: 0.6509 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.6309 - acc: 0.7125 - val_loss: 0.6479 - val_acc: 0.6000\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 300us/step - loss: 0.6254 - acc: 0.7125 - val_loss: 0.6452 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6212 - acc: 0.7125 - val_loss: 0.6416 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6180 - acc: 0.7125 - val_loss: 0.6395 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6127 - acc: 0.7125 - val_loss: 0.6345 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6058 - acc: 0.8000 - val_loss: 0.6311 - val_acc: 0.7500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6084 - acc: 0.7625 - val_loss: 0.6279 - val_acc: 0.8000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5957 - acc: 0.7875 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5944 - acc: 0.7250 - val_loss: 0.6253 - val_acc: 0.6000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5862 - acc: 0.7375 - val_loss: 0.6173 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5804 - acc: 0.8000 - val_loss: 0.6137 - val_acc: 0.7500\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5771 - acc: 0.7625 - val_loss: 0.6119 - val_acc: 0.7000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5690 - acc: 0.7875 - val_loss: 0.6061 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5651 - acc: 0.8000 - val_loss: 0.6023 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5587 - acc: 0.7750 - val_loss: 0.5996 - val_acc: 0.7500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5583 - acc: 0.7750 - val_loss: 0.6005 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5497 - acc: 0.8000 - val_loss: 0.5920 - val_acc: 0.7500\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5436 - acc: 0.7875 - val_loss: 0.5882 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5381 - acc: 0.7875 - val_loss: 0.5847 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5330 - acc: 0.8125 - val_loss: 0.5832 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5289 - acc: 0.8125 - val_loss: 0.5804 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5239 - acc: 0.8000 - val_loss: 0.5755 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.5203 - acc: 0.8125 - val_loss: 0.5729 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5188 - acc: 0.8000 - val_loss: 0.5654 - val_acc: 0.8000\n",
      "45 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.6921 - acc: 0.5000 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6907 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6878 - acc: 0.5000 - val_loss: 0.6864 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6864 - acc: 0.5000 - val_loss: 0.6857 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6852 - acc: 0.5000 - val_loss: 0.6850 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.6844 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6839 - acc: 0.5000 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6820 - acc: 0.5000 - val_loss: 0.6826 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6804 - acc: 0.5000 - val_loss: 0.6816 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6791 - acc: 0.5000 - val_loss: 0.6805 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6772 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6755 - acc: 0.5000 - val_loss: 0.6781 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6739 - acc: 0.5000 - val_loss: 0.6765 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6710 - acc: 0.5000 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 318us/step - loss: 0.6688 - acc: 0.5000 - val_loss: 0.6733 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6661 - acc: 0.5125 - val_loss: 0.6715 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6631 - acc: 0.5500 - val_loss: 0.6696 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6605 - acc: 0.5500 - val_loss: 0.6675 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6560 - acc: 0.5500 - val_loss: 0.6653 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6535 - acc: 0.6250 - val_loss: 0.6627 - val_acc: 0.5500\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6512 - acc: 0.6500 - val_loss: 0.6603 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6447 - acc: 0.6500 - val_loss: 0.6578 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6410 - acc: 0.6750 - val_loss: 0.6550 - val_acc: 0.5500\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6384 - acc: 0.7000 - val_loss: 0.6517 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 341us/step - loss: 0.6329 - acc: 0.7125 - val_loss: 0.6487 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6267 - acc: 0.7125 - val_loss: 0.6463 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.6250 - acc: 0.6875 - val_loss: 0.6441 - val_acc: 0.5500\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6191 - acc: 0.6750 - val_loss: 0.6406 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6131 - acc: 0.7125 - val_loss: 0.6363 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6107 - acc: 0.7250 - val_loss: 0.6324 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6085 - acc: 0.7250 - val_loss: 0.6315 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5990 - acc: 0.7125 - val_loss: 0.6276 - val_acc: 0.6000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5934 - acc: 0.7250 - val_loss: 0.6226 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5890 - acc: 0.7750 - val_loss: 0.6187 - val_acc: 0.7500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5830 - acc: 0.8000 - val_loss: 0.6156 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5784 - acc: 0.7750 - val_loss: 0.6139 - val_acc: 0.6500\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5723 - acc: 0.7750 - val_loss: 0.6103 - val_acc: 0.7000\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 326us/step - loss: 0.5701 - acc: 0.7625 - val_loss: 0.6083 - val_acc: 0.6000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5632 - acc: 0.7875 - val_loss: 0.6007 - val_acc: 0.7500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.5607 - acc: 0.8000 - val_loss: 0.5961 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5552 - acc: 0.7750 - val_loss: 0.5964 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 406us/step - loss: 0.5474 - acc: 0.7875 - val_loss: 0.5946 - val_acc: 0.7000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5424 - acc: 0.7875 - val_loss: 0.5898 - val_acc: 0.7000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 315us/step - loss: 0.5374 - acc: 0.8250 - val_loss: 0.5835 - val_acc: 0.7500\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5324 - acc: 0.8000 - val_loss: 0.5798 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.5278 - acc: 0.7875 - val_loss: 0.5759 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.5231 - acc: 0.8000 - val_loss: 0.5735 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5216 - acc: 0.7875 - val_loss: 0.5686 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.5127 - acc: 0.8000 - val_loss: 0.5697 - val_acc: 0.7500\n",
      "50 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.6898 - acc: 0.5000 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.6871 - acc: 0.5000 - val_loss: 0.6856 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6851 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6847 - acc: 0.5000 - val_loss: 0.6842 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6838 - acc: 0.5000 - val_loss: 0.6836 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6829 - acc: 0.5000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6817 - acc: 0.5000 - val_loss: 0.6819 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6807 - acc: 0.5000 - val_loss: 0.6811 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6800 - acc: 0.5000 - val_loss: 0.6802 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6773 - acc: 0.5000 - val_loss: 0.6791 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6757 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6742 - acc: 0.5000 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6717 - acc: 0.5000 - val_loss: 0.6754 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6695 - acc: 0.5000 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6677 - acc: 0.5000 - val_loss: 0.6722 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6648 - acc: 0.5125 - val_loss: 0.6704 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6628 - acc: 0.6000 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.6586 - acc: 0.5750 - val_loss: 0.6664 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6566 - acc: 0.5625 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6542 - acc: 0.6250 - val_loss: 0.6619 - val_acc: 0.5500\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6483 - acc: 0.6750 - val_loss: 0.6594 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6468 - acc: 0.6875 - val_loss: 0.6568 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6398 - acc: 0.7125 - val_loss: 0.6540 - val_acc: 0.6000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6353 - acc: 0.7125 - val_loss: 0.6513 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6326 - acc: 0.7125 - val_loss: 0.6481 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6256 - acc: 0.7125 - val_loss: 0.6455 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6228 - acc: 0.7125 - val_loss: 0.6418 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6174 - acc: 0.7250 - val_loss: 0.6382 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6111 - acc: 0.7625 - val_loss: 0.6344 - val_acc: 0.6500\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6062 - acc: 0.7125 - val_loss: 0.6310 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5997 - acc: 0.7375 - val_loss: 0.6271 - val_acc: 0.6500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5946 - acc: 0.7500 - val_loss: 0.6231 - val_acc: 0.7000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5941 - acc: 0.7875 - val_loss: 0.6182 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5824 - acc: 0.8125 - val_loss: 0.6151 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5834 - acc: 0.7625 - val_loss: 0.6178 - val_acc: 0.6000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5706 - acc: 0.7500 - val_loss: 0.6080 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5662 - acc: 0.7875 - val_loss: 0.6020 - val_acc: 0.8000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5617 - acc: 0.7750 - val_loss: 0.5987 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5531 - acc: 0.8000 - val_loss: 0.5950 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5477 - acc: 0.8000 - val_loss: 0.5934 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5432 - acc: 0.7750 - val_loss: 0.5894 - val_acc: 0.7000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5440 - acc: 0.7625 - val_loss: 0.5809 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5314 - acc: 0.7875 - val_loss: 0.5779 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5259 - acc: 0.8000 - val_loss: 0.5796 - val_acc: 0.7000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5222 - acc: 0.7750 - val_loss: 0.5715 - val_acc: 0.7500\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.5210 - acc: 0.7875 - val_loss: 0.5643 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5151 - acc: 0.8000 - val_loss: 0.5656 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5052 - acc: 0.8000 - val_loss: 0.5601 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5012 - acc: 0.8000 - val_loss: 0.5603 - val_acc: 0.7500\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 333us/step - loss: 0.4942 - acc: 0.8000 - val_loss: 0.5521 - val_acc: 0.8000\n",
      "55 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6864 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6883 - acc: 0.5000 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6850 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6838 - acc: 0.5000 - val_loss: 0.6832 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6824 - acc: 0.5000 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6805 - acc: 0.5000 - val_loss: 0.6812 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6787 - acc: 0.5000 - val_loss: 0.6802 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6777 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6761 - acc: 0.5000 - val_loss: 0.6781 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6750 - acc: 0.5250 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6742 - acc: 0.5125 - val_loss: 0.6751 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6699 - acc: 0.5000 - val_loss: 0.6737 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6671 - acc: 0.5250 - val_loss: 0.6721 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6646 - acc: 0.5500 - val_loss: 0.6703 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6615 - acc: 0.5500 - val_loss: 0.6685 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.6602 - acc: 0.6125 - val_loss: 0.6666 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6552 - acc: 0.6375 - val_loss: 0.6646 - val_acc: 0.5500\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6523 - acc: 0.7125 - val_loss: 0.6623 - val_acc: 0.5500\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6483 - acc: 0.6875 - val_loss: 0.6598 - val_acc: 0.5500\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6446 - acc: 0.6875 - val_loss: 0.6573 - val_acc: 0.5500\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6432 - acc: 0.6250 - val_loss: 0.6555 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6371 - acc: 0.7000 - val_loss: 0.6516 - val_acc: 0.6000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6330 - acc: 0.7500 - val_loss: 0.6489 - val_acc: 0.7000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6291 - acc: 0.7250 - val_loss: 0.6454 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6211 - acc: 0.7125 - val_loss: 0.6419 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6159 - acc: 0.7375 - val_loss: 0.6382 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.6105 - acc: 0.7625 - val_loss: 0.6343 - val_acc: 0.7000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6053 - acc: 0.8000 - val_loss: 0.6304 - val_acc: 0.7000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.6008 - acc: 0.7375 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5946 - acc: 0.7875 - val_loss: 0.6221 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5879 - acc: 0.7875 - val_loss: 0.6191 - val_acc: 0.6500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5844 - acc: 0.7750 - val_loss: 0.6133 - val_acc: 0.8000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.5749 - acc: 0.7750 - val_loss: 0.6102 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5676 - acc: 0.7750 - val_loss: 0.6060 - val_acc: 0.7000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5680 - acc: 0.7500 - val_loss: 0.6000 - val_acc: 0.8000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5571 - acc: 0.8250 - val_loss: 0.6002 - val_acc: 0.7000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5527 - acc: 0.7625 - val_loss: 0.5969 - val_acc: 0.7000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5426 - acc: 0.8125 - val_loss: 0.5875 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5443 - acc: 0.7750 - val_loss: 0.5821 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5302 - acc: 0.7875 - val_loss: 0.5794 - val_acc: 0.7500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 323us/step - loss: 0.5321 - acc: 0.7875 - val_loss: 0.5860 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5209 - acc: 0.7875 - val_loss: 0.5705 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5148 - acc: 0.7875 - val_loss: 0.5663 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5095 - acc: 0.7750 - val_loss: 0.5616 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.5061 - acc: 0.8000 - val_loss: 0.5623 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5005 - acc: 0.7750 - val_loss: 0.5547 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.4968 - acc: 0.7875 - val_loss: 0.5505 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.4945 - acc: 0.8000 - val_loss: 0.5556 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.4884 - acc: 0.7750 - val_loss: 0.5429 - val_acc: 0.8000\n",
      "60 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6884 - acc: 0.5000 - val_loss: 0.6867 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6872 - acc: 0.5000 - val_loss: 0.6856 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6856 - acc: 0.5000 - val_loss: 0.6846 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.6842 - acc: 0.5000 - val_loss: 0.6832 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6821 - acc: 0.5000 - val_loss: 0.6821 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 476us/step - loss: 0.6802 - acc: 0.5000 - val_loss: 0.6809 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 476us/step - loss: 0.6803 - acc: 0.5000 - val_loss: 0.6800 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 464us/step - loss: 0.6768 - acc: 0.5000 - val_loss: 0.6785 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.6742 - acc: 0.5000 - val_loss: 0.6771 - val_acc: 0.5000\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 376us/step - loss: 0.6766 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6706 - acc: 0.5000 - val_loss: 0.6741 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6683 - acc: 0.5375 - val_loss: 0.6725 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 466us/step - loss: 0.6644 - acc: 0.5500 - val_loss: 0.6705 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 392us/step - loss: 0.6630 - acc: 0.5875 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6588 - acc: 0.6125 - val_loss: 0.6663 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6545 - acc: 0.5500 - val_loss: 0.6637 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6504 - acc: 0.5875 - val_loss: 0.6609 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6464 - acc: 0.6500 - val_loss: 0.6579 - val_acc: 0.6000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6415 - acc: 0.7125 - val_loss: 0.6547 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6383 - acc: 0.7125 - val_loss: 0.6522 - val_acc: 0.5500\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 418us/step - loss: 0.6315 - acc: 0.6875 - val_loss: 0.6483 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6281 - acc: 0.7625 - val_loss: 0.6448 - val_acc: 0.7000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6202 - acc: 0.7875 - val_loss: 0.6408 - val_acc: 0.6500\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6167 - acc: 0.7000 - val_loss: 0.6382 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6085 - acc: 0.7125 - val_loss: 0.6331 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.6044 - acc: 0.7125 - val_loss: 0.6295 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5941 - acc: 0.7750 - val_loss: 0.6238 - val_acc: 0.7500\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 464us/step - loss: 0.5896 - acc: 0.8000 - val_loss: 0.6194 - val_acc: 0.7500\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5826 - acc: 0.8000 - val_loss: 0.6148 - val_acc: 0.7500\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.5744 - acc: 0.8250 - val_loss: 0.6111 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5696 - acc: 0.7750 - val_loss: 0.6064 - val_acc: 0.7000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5616 - acc: 0.8250 - val_loss: 0.6009 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5542 - acc: 0.8125 - val_loss: 0.5964 - val_acc: 0.7500\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5477 - acc: 0.8000 - val_loss: 0.5903 - val_acc: 0.7500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.5415 - acc: 0.8000 - val_loss: 0.5865 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.5347 - acc: 0.8000 - val_loss: 0.5823 - val_acc: 0.7500\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5295 - acc: 0.7750 - val_loss: 0.5763 - val_acc: 0.8000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 361us/step - loss: 0.5229 - acc: 0.8000 - val_loss: 0.5727 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5181 - acc: 0.7875 - val_loss: 0.5659 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5099 - acc: 0.8000 - val_loss: 0.5686 - val_acc: 0.7500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5033 - acc: 0.8125 - val_loss: 0.5617 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5072 - acc: 0.7875 - val_loss: 0.5517 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4964 - acc: 0.7750 - val_loss: 0.5632 - val_acc: 0.7000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4925 - acc: 0.7875 - val_loss: 0.5484 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4859 - acc: 0.7750 - val_loss: 0.5441 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4795 - acc: 0.7875 - val_loss: 0.5382 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4740 - acc: 0.7875 - val_loss: 0.5408 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.4721 - acc: 0.7875 - val_loss: 0.5331 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4650 - acc: 0.7750 - val_loss: 0.5285 - val_acc: 0.8000\n",
      "65 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.6952 - acc: 0.4750 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6902 - acc: 0.5000 - val_loss: 0.6869 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6863 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6859 - acc: 0.5000 - val_loss: 0.6853 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6891 - acc: 0.5000 - val_loss: 0.6841 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6833 - acc: 0.5000 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6826 - acc: 0.5000 - val_loss: 0.6827 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6803 - acc: 0.5000 - val_loss: 0.6816 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6789 - acc: 0.5000 - val_loss: 0.6804 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6774 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6756 - acc: 0.5000 - val_loss: 0.6782 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6733 - acc: 0.5000 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 355us/step - loss: 0.6725 - acc: 0.5000 - val_loss: 0.6757 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6689 - acc: 0.5500 - val_loss: 0.6740 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6669 - acc: 0.5375 - val_loss: 0.6723 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6645 - acc: 0.5375 - val_loss: 0.6705 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6617 - acc: 0.5500 - val_loss: 0.6688 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6585 - acc: 0.5500 - val_loss: 0.6665 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6559 - acc: 0.6250 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6533 - acc: 0.6875 - val_loss: 0.6624 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6483 - acc: 0.6500 - val_loss: 0.6600 - val_acc: 0.5000\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 390us/step - loss: 0.6448 - acc: 0.6750 - val_loss: 0.6576 - val_acc: 0.5500\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.6407 - acc: 0.6875 - val_loss: 0.6548 - val_acc: 0.5500\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6363 - acc: 0.7000 - val_loss: 0.6519 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6324 - acc: 0.7125 - val_loss: 0.6489 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6273 - acc: 0.7125 - val_loss: 0.6461 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6226 - acc: 0.7250 - val_loss: 0.6426 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6171 - acc: 0.7250 - val_loss: 0.6393 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6126 - acc: 0.7625 - val_loss: 0.6357 - val_acc: 0.7000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6082 - acc: 0.7500 - val_loss: 0.6332 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6075 - acc: 0.7250 - val_loss: 0.6284 - val_acc: 0.7500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 378us/step - loss: 0.5983 - acc: 0.7750 - val_loss: 0.6262 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5903 - acc: 0.7250 - val_loss: 0.6222 - val_acc: 0.6500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5876 - acc: 0.7250 - val_loss: 0.6181 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.5812 - acc: 0.8250 - val_loss: 0.6131 - val_acc: 0.7500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5754 - acc: 0.7875 - val_loss: 0.6092 - val_acc: 0.8000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.5686 - acc: 0.7750 - val_loss: 0.6063 - val_acc: 0.7000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5630 - acc: 0.7750 - val_loss: 0.6043 - val_acc: 0.7000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5634 - acc: 0.7625 - val_loss: 0.5972 - val_acc: 0.8000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5508 - acc: 0.7875 - val_loss: 0.5954 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5453 - acc: 0.8000 - val_loss: 0.5928 - val_acc: 0.7000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5424 - acc: 0.7750 - val_loss: 0.5898 - val_acc: 0.7000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.5398 - acc: 0.7875 - val_loss: 0.5809 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5324 - acc: 0.8000 - val_loss: 0.5794 - val_acc: 0.7500\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5272 - acc: 0.7875 - val_loss: 0.5735 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5190 - acc: 0.7875 - val_loss: 0.5758 - val_acc: 0.7000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.5147 - acc: 0.7875 - val_loss: 0.5675 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5088 - acc: 0.7875 - val_loss: 0.5630 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5034 - acc: 0.8000 - val_loss: 0.5623 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.4992 - acc: 0.8000 - val_loss: 0.5590 - val_acc: 0.7500\n",
      "70 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6900 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6886 - acc: 0.5000 - val_loss: 0.6874 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6870 - acc: 0.5000 - val_loss: 0.6867 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6863 - acc: 0.5000 - val_loss: 0.6859 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6858 - acc: 0.5000 - val_loss: 0.6853 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6844 - acc: 0.5000 - val_loss: 0.6844 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6834 - acc: 0.5000 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6830 - acc: 0.5000 - val_loss: 0.6828 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.6808 - acc: 0.5000 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6789 - acc: 0.5000 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6774 - acc: 0.5000 - val_loss: 0.6795 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6757 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6732 - acc: 0.5125 - val_loss: 0.6767 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6713 - acc: 0.5375 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6676 - acc: 0.5500 - val_loss: 0.6730 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6657 - acc: 0.5750 - val_loss: 0.6712 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6611 - acc: 0.6250 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6589 - acc: 0.5625 - val_loss: 0.6663 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6568 - acc: 0.6375 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6502 - acc: 0.6875 - val_loss: 0.6609 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6479 - acc: 0.6875 - val_loss: 0.6579 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6442 - acc: 0.6625 - val_loss: 0.6558 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6353 - acc: 0.6750 - val_loss: 0.6518 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6329 - acc: 0.7875 - val_loss: 0.6487 - val_acc: 0.7000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6257 - acc: 0.7750 - val_loss: 0.6447 - val_acc: 0.6500\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6192 - acc: 0.7375 - val_loss: 0.6411 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6153 - acc: 0.7875 - val_loss: 0.6371 - val_acc: 0.7000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6072 - acc: 0.7625 - val_loss: 0.6338 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6037 - acc: 0.7125 - val_loss: 0.6314 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5965 - acc: 0.7375 - val_loss: 0.6252 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5920 - acc: 0.7625 - val_loss: 0.6206 - val_acc: 0.7000\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 376us/step - loss: 0.5830 - acc: 0.8000 - val_loss: 0.6162 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.5776 - acc: 0.8000 - val_loss: 0.6117 - val_acc: 0.8000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5708 - acc: 0.8000 - val_loss: 0.6081 - val_acc: 0.7500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.5651 - acc: 0.7875 - val_loss: 0.6041 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5604 - acc: 0.7750 - val_loss: 0.5984 - val_acc: 0.8000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5513 - acc: 0.8000 - val_loss: 0.5951 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5489 - acc: 0.7875 - val_loss: 0.5964 - val_acc: 0.7000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5403 - acc: 0.7875 - val_loss: 0.5888 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5356 - acc: 0.7750 - val_loss: 0.5805 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.5296 - acc: 0.7875 - val_loss: 0.5772 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.5232 - acc: 0.7875 - val_loss: 0.5788 - val_acc: 0.7000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5162 - acc: 0.8000 - val_loss: 0.5720 - val_acc: 0.7500\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5108 - acc: 0.8000 - val_loss: 0.5656 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 365us/step - loss: 0.5105 - acc: 0.7750 - val_loss: 0.5595 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.4997 - acc: 0.7750 - val_loss: 0.5604 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.4971 - acc: 0.8000 - val_loss: 0.5588 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4917 - acc: 0.8000 - val_loss: 0.5561 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4856 - acc: 0.7875 - val_loss: 0.5451 - val_acc: 0.8000\n",
      "75 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.6913 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6862 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6870 - acc: 0.5000 - val_loss: 0.6854 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 366us/step - loss: 0.6860 - acc: 0.5000 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6844 - acc: 0.5000 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6820 - acc: 0.5000 - val_loss: 0.6823 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6808 - acc: 0.5000 - val_loss: 0.6813 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6821 - acc: 0.5000 - val_loss: 0.6810 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6785 - acc: 0.5000 - val_loss: 0.6798 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6757 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6739 - acc: 0.5000 - val_loss: 0.6766 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6716 - acc: 0.5000 - val_loss: 0.6752 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6702 - acc: 0.5000 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6678 - acc: 0.5125 - val_loss: 0.6722 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6661 - acc: 0.5250 - val_loss: 0.6705 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6675 - acc: 0.6000 - val_loss: 0.6694 - val_acc: 0.5500\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6599 - acc: 0.6375 - val_loss: 0.6669 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6564 - acc: 0.5500 - val_loss: 0.6648 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6530 - acc: 0.5500 - val_loss: 0.6629 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 390us/step - loss: 0.6523 - acc: 0.5625 - val_loss: 0.6612 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6463 - acc: 0.6000 - val_loss: 0.6578 - val_acc: 0.5500\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6431 - acc: 0.6875 - val_loss: 0.6553 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6389 - acc: 0.7125 - val_loss: 0.6526 - val_acc: 0.6000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 365us/step - loss: 0.6353 - acc: 0.6875 - val_loss: 0.6504 - val_acc: 0.5500\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6291 - acc: 0.6875 - val_loss: 0.6475 - val_acc: 0.5500\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6249 - acc: 0.7000 - val_loss: 0.6439 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6204 - acc: 0.7000 - val_loss: 0.6405 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6147 - acc: 0.7125 - val_loss: 0.6372 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6129 - acc: 0.7125 - val_loss: 0.6362 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6069 - acc: 0.7500 - val_loss: 0.6295 - val_acc: 0.7000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6007 - acc: 0.7375 - val_loss: 0.6262 - val_acc: 0.6500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5931 - acc: 0.7750 - val_loss: 0.6227 - val_acc: 0.6500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 370us/step - loss: 0.5869 - acc: 0.7750 - val_loss: 0.6187 - val_acc: 0.7000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5824 - acc: 0.7625 - val_loss: 0.6137 - val_acc: 0.7500\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5764 - acc: 0.8000 - val_loss: 0.6098 - val_acc: 0.7500\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5716 - acc: 0.7875 - val_loss: 0.6072 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.5645 - acc: 0.7875 - val_loss: 0.6051 - val_acc: 0.7000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5579 - acc: 0.7875 - val_loss: 0.5979 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5558 - acc: 0.7875 - val_loss: 0.5928 - val_acc: 0.8000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5455 - acc: 0.8125 - val_loss: 0.5903 - val_acc: 0.7500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5436 - acc: 0.7875 - val_loss: 0.5927 - val_acc: 0.7000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5399 - acc: 0.7875 - val_loss: 0.5812 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5323 - acc: 0.7875 - val_loss: 0.5760 - val_acc: 0.8000\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 389us/step - loss: 0.5315 - acc: 0.7875 - val_loss: 0.5793 - val_acc: 0.7000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5262 - acc: 0.7625 - val_loss: 0.5698 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5145 - acc: 0.7750 - val_loss: 0.5677 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5140 - acc: 0.7750 - val_loss: 0.5729 - val_acc: 0.7000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5066 - acc: 0.8250 - val_loss: 0.5584 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5022 - acc: 0.8000 - val_loss: 0.5540 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.4988 - acc: 0.7750 - val_loss: 0.5521 - val_acc: 0.8000\n",
      "80 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.6978 - acc: 0.4750 - val_loss: 0.6873 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6878 - acc: 0.5000 - val_loss: 0.6863 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6864 - acc: 0.5000 - val_loss: 0.6854 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6845 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6831 - acc: 0.5000 - val_loss: 0.6835 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6818 - acc: 0.5000 - val_loss: 0.6826 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6802 - acc: 0.5000 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6792 - acc: 0.5000 - val_loss: 0.6809 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6775 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6750 - acc: 0.5000 - val_loss: 0.6782 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6743 - acc: 0.5000 - val_loss: 0.6766 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6703 - acc: 0.5000 - val_loss: 0.6749 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6681 - acc: 0.5250 - val_loss: 0.6733 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6654 - acc: 0.5500 - val_loss: 0.6712 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6618 - acc: 0.5500 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 352us/step - loss: 0.6585 - acc: 0.5875 - val_loss: 0.6665 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6549 - acc: 0.6000 - val_loss: 0.6639 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6498 - acc: 0.6250 - val_loss: 0.6613 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6464 - acc: 0.6875 - val_loss: 0.6583 - val_acc: 0.6000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6429 - acc: 0.7250 - val_loss: 0.6553 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6350 - acc: 0.7000 - val_loss: 0.6516 - val_acc: 0.6000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6320 - acc: 0.7125 - val_loss: 0.6482 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6320 - acc: 0.6375 - val_loss: 0.6486 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6206 - acc: 0.7000 - val_loss: 0.6410 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6157 - acc: 0.7500 - val_loss: 0.6365 - val_acc: 0.7000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6112 - acc: 0.7750 - val_loss: 0.6326 - val_acc: 0.8000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6007 - acc: 0.7875 - val_loss: 0.6286 - val_acc: 0.7000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6004 - acc: 0.7125 - val_loss: 0.6292 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.5934 - acc: 0.7250 - val_loss: 0.6199 - val_acc: 0.7500\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.5878 - acc: 0.7875 - val_loss: 0.6158 - val_acc: 0.8000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.5763 - acc: 0.8125 - val_loss: 0.6117 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5731 - acc: 0.7625 - val_loss: 0.6118 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5678 - acc: 0.7500 - val_loss: 0.6036 - val_acc: 0.7000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5618 - acc: 0.7750 - val_loss: 0.5978 - val_acc: 0.8000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.5547 - acc: 0.7750 - val_loss: 0.5976 - val_acc: 0.7000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5467 - acc: 0.7875 - val_loss: 0.5936 - val_acc: 0.7000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5395 - acc: 0.8000 - val_loss: 0.5848 - val_acc: 0.8000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5344 - acc: 0.7875 - val_loss: 0.5800 - val_acc: 0.8000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5276 - acc: 0.7875 - val_loss: 0.5809 - val_acc: 0.7000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5211 - acc: 0.8125 - val_loss: 0.5758 - val_acc: 0.7500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5185 - acc: 0.8000 - val_loss: 0.5673 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5102 - acc: 0.7875 - val_loss: 0.5665 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5064 - acc: 0.8000 - val_loss: 0.5636 - val_acc: 0.7500\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4995 - acc: 0.8000 - val_loss: 0.5569 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4934 - acc: 0.7875 - val_loss: 0.5522 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4910 - acc: 0.7625 - val_loss: 0.5489 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.4920 - acc: 0.7625 - val_loss: 0.5429 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.4800 - acc: 0.8000 - val_loss: 0.5568 - val_acc: 0.7000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.4827 - acc: 0.7875 - val_loss: 0.5530 - val_acc: 0.7000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4700 - acc: 0.8125 - val_loss: 0.5305 - val_acc: 0.7500\n",
      "85 0.8\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.6942 - acc: 0.4875 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 414us/step - loss: 0.6916 - acc: 0.5250 - val_loss: 0.6861 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6859 - acc: 0.5000 - val_loss: 0.6850 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6837 - acc: 0.5000 - val_loss: 0.6838 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6840 - acc: 0.5000 - val_loss: 0.6828 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6793 - acc: 0.5000 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6773 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 326us/step - loss: 0.6753 - acc: 0.5000 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6729 - acc: 0.5000 - val_loss: 0.6766 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6706 - acc: 0.5250 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6683 - acc: 0.5250 - val_loss: 0.6734 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6658 - acc: 0.5625 - val_loss: 0.6713 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 390us/step - loss: 0.6635 - acc: 0.5500 - val_loss: 0.6694 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6589 - acc: 0.5750 - val_loss: 0.6674 - val_acc: 0.5500\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6564 - acc: 0.7000 - val_loss: 0.6652 - val_acc: 0.6000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6515 - acc: 0.6875 - val_loss: 0.6624 - val_acc: 0.5500\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6503 - acc: 0.5875 - val_loss: 0.6601 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6438 - acc: 0.6875 - val_loss: 0.6571 - val_acc: 0.6000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6405 - acc: 0.7125 - val_loss: 0.6543 - val_acc: 0.6500\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.6384 - acc: 0.7000 - val_loss: 0.6518 - val_acc: 0.5500\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6302 - acc: 0.7000 - val_loss: 0.6478 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6239 - acc: 0.7375 - val_loss: 0.6444 - val_acc: 0.6000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6210 - acc: 0.7500 - val_loss: 0.6416 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.6120 - acc: 0.7250 - val_loss: 0.6372 - val_acc: 0.6500\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6084 - acc: 0.7875 - val_loss: 0.6333 - val_acc: 0.7500\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6022 - acc: 0.8000 - val_loss: 0.6291 - val_acc: 0.7000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5955 - acc: 0.7750 - val_loss: 0.6251 - val_acc: 0.7000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5886 - acc: 0.7750 - val_loss: 0.6206 - val_acc: 0.7000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5822 - acc: 0.8000 - val_loss: 0.6167 - val_acc: 0.7000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5766 - acc: 0.7875 - val_loss: 0.6124 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.5684 - acc: 0.7750 - val_loss: 0.6071 - val_acc: 0.7500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5635 - acc: 0.8000 - val_loss: 0.6023 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5598 - acc: 0.7875 - val_loss: 0.5973 - val_acc: 0.8000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5536 - acc: 0.7875 - val_loss: 0.5962 - val_acc: 0.7000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 333us/step - loss: 0.5441 - acc: 0.8125 - val_loss: 0.5897 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5375 - acc: 0.8000 - val_loss: 0.5847 - val_acc: 0.8000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.5363 - acc: 0.7625 - val_loss: 0.5797 - val_acc: 0.8000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5251 - acc: 0.7875 - val_loss: 0.5771 - val_acc: 0.8000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5271 - acc: 0.8000 - val_loss: 0.5803 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5169 - acc: 0.7875 - val_loss: 0.5688 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.5131 - acc: 0.7875 - val_loss: 0.5673 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5056 - acc: 0.8000 - val_loss: 0.5600 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5007 - acc: 0.7750 - val_loss: 0.5579 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.5035 - acc: 0.7750 - val_loss: 0.5514 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4977 - acc: 0.7875 - val_loss: 0.5560 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4882 - acc: 0.8000 - val_loss: 0.5491 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.4825 - acc: 0.7875 - val_loss: 0.5436 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4810 - acc: 0.7875 - val_loss: 0.5387 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.4752 - acc: 0.8000 - val_loss: 0.5376 - val_acc: 0.8000\n",
      "90 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.6896 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6863 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6851 - acc: 0.5000 - val_loss: 0.6838 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6829 - acc: 0.5000 - val_loss: 0.6826 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 339us/step - loss: 0.6814 - acc: 0.5000 - val_loss: 0.6816 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6789 - acc: 0.5000 - val_loss: 0.6806 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6774 - acc: 0.5000 - val_loss: 0.6793 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6758 - acc: 0.5000 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6724 - acc: 0.5000 - val_loss: 0.6767 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6709 - acc: 0.5250 - val_loss: 0.6753 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6683 - acc: 0.5500 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.6658 - acc: 0.5750 - val_loss: 0.6720 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6640 - acc: 0.5625 - val_loss: 0.6699 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.6603 - acc: 0.5625 - val_loss: 0.6678 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6566 - acc: 0.6625 - val_loss: 0.6656 - val_acc: 0.5000\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 363us/step - loss: 0.6596 - acc: 0.5500 - val_loss: 0.6639 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6496 - acc: 0.6500 - val_loss: 0.6608 - val_acc: 0.5500\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6472 - acc: 0.7250 - val_loss: 0.6585 - val_acc: 0.6000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6409 - acc: 0.7125 - val_loss: 0.6555 - val_acc: 0.6000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.6360 - acc: 0.7125 - val_loss: 0.6524 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6320 - acc: 0.7125 - val_loss: 0.6489 - val_acc: 0.6000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6255 - acc: 0.7125 - val_loss: 0.6457 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6227 - acc: 0.7000 - val_loss: 0.6437 - val_acc: 0.5500\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 402us/step - loss: 0.6187 - acc: 0.7000 - val_loss: 0.6379 - val_acc: 0.7000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6097 - acc: 0.8000 - val_loss: 0.6339 - val_acc: 0.7000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6023 - acc: 0.7750 - val_loss: 0.6304 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5974 - acc: 0.7250 - val_loss: 0.6273 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5905 - acc: 0.7375 - val_loss: 0.6203 - val_acc: 0.7500\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5836 - acc: 0.7750 - val_loss: 0.6155 - val_acc: 0.8000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5843 - acc: 0.7625 - val_loss: 0.6160 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5712 - acc: 0.7750 - val_loss: 0.6066 - val_acc: 0.7500\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5636 - acc: 0.8000 - val_loss: 0.6008 - val_acc: 0.8000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5554 - acc: 0.7750 - val_loss: 0.5977 - val_acc: 0.7500\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5503 - acc: 0.7750 - val_loss: 0.5958 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5435 - acc: 0.7750 - val_loss: 0.5860 - val_acc: 0.8000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.5347 - acc: 0.7750 - val_loss: 0.5820 - val_acc: 0.8000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5307 - acc: 0.8000 - val_loss: 0.5783 - val_acc: 0.7500\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5225 - acc: 0.7750 - val_loss: 0.5731 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.5143 - acc: 0.8000 - val_loss: 0.5712 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5099 - acc: 0.8125 - val_loss: 0.5674 - val_acc: 0.7500\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.5036 - acc: 0.7875 - val_loss: 0.5560 - val_acc: 0.8000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.5020 - acc: 0.7750 - val_loss: 0.5531 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4913 - acc: 0.7750 - val_loss: 0.5527 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.4863 - acc: 0.8125 - val_loss: 0.5498 - val_acc: 0.7500\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 351us/step - loss: 0.4814 - acc: 0.7750 - val_loss: 0.5413 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.4792 - acc: 0.7875 - val_loss: 0.5446 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4734 - acc: 0.7875 - val_loss: 0.5356 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.4722 - acc: 0.7875 - val_loss: 0.5264 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.4689 - acc: 0.8000 - val_loss: 0.5397 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4628 - acc: 0.8000 - val_loss: 0.5317 - val_acc: 0.8000\n",
      "95 0.85\n",
      " \n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6941 - acc: 0.4250 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6904 - acc: 0.5000 - val_loss: 0.6859 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6868 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.6846 - acc: 0.5000 - val_loss: 0.6838 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.6832 - acc: 0.5000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.6820 - acc: 0.5000 - val_loss: 0.6817 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6797 - acc: 0.5000 - val_loss: 0.6805 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6774 - acc: 0.5000 - val_loss: 0.6794 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 0s 401us/step - loss: 0.6764 - acc: 0.5000 - val_loss: 0.6777 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6739 - acc: 0.5125 - val_loss: 0.6766 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6701 - acc: 0.5500 - val_loss: 0.6748 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6686 - acc: 0.5500 - val_loss: 0.6727 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.6659 - acc: 0.5250 - val_loss: 0.6708 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6620 - acc: 0.5500 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6574 - acc: 0.6000 - val_loss: 0.6665 - val_acc: 0.5500\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6545 - acc: 0.7125 - val_loss: 0.6640 - val_acc: 0.6000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.6521 - acc: 0.6750 - val_loss: 0.6610 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.6506 - acc: 0.7125 - val_loss: 0.6589 - val_acc: 0.7000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.6434 - acc: 0.7000 - val_loss: 0.6556 - val_acc: 0.5500\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6369 - acc: 0.6625 - val_loss: 0.6525 - val_acc: 0.5500\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.6319 - acc: 0.7125 - val_loss: 0.6484 - val_acc: 0.6000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6263 - acc: 0.7750 - val_loss: 0.6450 - val_acc: 0.7000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6230 - acc: 0.7500 - val_loss: 0.6419 - val_acc: 0.6000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6144 - acc: 0.7125 - val_loss: 0.6379 - val_acc: 0.6000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6134 - acc: 0.7625 - val_loss: 0.6342 - val_acc: 0.8000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.6047 - acc: 0.8000 - val_loss: 0.6295 - val_acc: 0.7000\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 376us/step - loss: 0.5969 - acc: 0.7625 - val_loss: 0.6254 - val_acc: 0.7000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.5897 - acc: 0.7750 - val_loss: 0.6214 - val_acc: 0.7000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5856 - acc: 0.7250 - val_loss: 0.6180 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5754 - acc: 0.8000 - val_loss: 0.6113 - val_acc: 0.8000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 0s 413us/step - loss: 0.5707 - acc: 0.7875 - val_loss: 0.6064 - val_acc: 0.8000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.5667 - acc: 0.7750 - val_loss: 0.6027 - val_acc: 0.7500\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5563 - acc: 0.8000 - val_loss: 0.5999 - val_acc: 0.7000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5520 - acc: 0.7875 - val_loss: 0.5946 - val_acc: 0.7000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.5443 - acc: 0.7875 - val_loss: 0.5869 - val_acc: 0.8000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5384 - acc: 0.8000 - val_loss: 0.5837 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5295 - acc: 0.7750 - val_loss: 0.5788 - val_acc: 0.8000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5236 - acc: 0.8000 - val_loss: 0.5766 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 0s 389us/step - loss: 0.5197 - acc: 0.8000 - val_loss: 0.5720 - val_acc: 0.7500\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.5143 - acc: 0.7875 - val_loss: 0.5638 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5076 - acc: 0.7875 - val_loss: 0.5639 - val_acc: 0.7500\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 0s 364us/step - loss: 0.4995 - acc: 0.8125 - val_loss: 0.5595 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 0s 402us/step - loss: 0.4953 - acc: 0.7875 - val_loss: 0.5515 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 0s 377us/step - loss: 0.4904 - acc: 0.7750 - val_loss: 0.5485 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4870 - acc: 0.7625 - val_loss: 0.5443 - val_acc: 0.8000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.4776 - acc: 0.7750 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.4791 - acc: 0.7875 - val_loss: 0.5417 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 0s 439us/step - loss: 0.4726 - acc: 0.7875 - val_loss: 0.5353 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 0s 451us/step - loss: 0.4739 - acc: 0.7875 - val_loss: 0.5408 - val_acc: 0.7500\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.4724 - acc: 0.7750 - val_loss: 0.5230 - val_acc: 0.7500\n",
      "100 0.8\n",
      " \n"
     ]
    }
   ],
   "source": [
    "freq=5   ### FREQUENCY VECTOR DECIDER\n",
    "neuron_variation=list(range(5,101,5)) # No. of neurons varys from 5 to 100 in step of 5\n",
    "Accuracy_neuron=[] \n",
    "for hid1 in neuron_variation:\n",
    "    train_features=extract_features(train_data,freq)\n",
    "    valid_features=extract_features(valid_data,freq)\n",
    "    test_features=extract_features(test_data,freq)\n",
    "\n",
    "    train_labels=train_labels.reshape((train_labels.shape[0],1))\n",
    "    valid_labels=valid_labels.reshape((valid_labels.shape[0],1))\n",
    "    test_labels=test_labels.reshape((test_labels.shape[0],1))\n",
    "    classifier=train(train_features,train_labels,valid_features,valid_labels,hid1,verb=1,epochs=100)\n",
    "    test_out=classifier.predict(test_features)\n",
    "    test_predict=test_out>0.5\n",
    "    accuracy=(test_predict==test_labels).sum()/20.0\n",
    "    print (hid1,accuracy)\n",
    "    Accuracy_neuron.append(accuracy)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5.      0.65]\n",
      " [  10.      0.65]\n",
      " [  15.      0.85]\n",
      " [  20.      0.8 ]\n",
      " [  25.      0.8 ]\n",
      " [  30.      0.8 ]\n",
      " [  35.      0.85]\n",
      " [  40.      0.85]\n",
      " [  45.      0.85]\n",
      " [  50.      0.85]\n",
      " [  55.      0.85]\n",
      " [  60.      0.85]\n",
      " [  65.      0.85]\n",
      " [  70.      0.85]\n",
      " [  75.      0.85]\n",
      " [  80.      0.85]\n",
      " [  85.      0.8 ]\n",
      " [  90.      0.85]\n",
      " [  95.      0.85]\n",
      " [ 100.      0.8 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.vstack([neuron_variation, Accuracy_neuron]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.45\n",
      "2 0.55\n",
      "3 0.8\n",
      "4 0.8\n",
      "5 0.85\n",
      "6 0.85\n",
      "7 0.8\n",
      "8 0.8\n"
     ]
    }
   ],
   "source": [
    "hid_neuron=50 ## No. of neurons in hidden layer\n",
    "frequency_variation=list(range(1,9,1)) ## Frequency decider varies from 1 to 8\n",
    "Accuracy_freq=[]\n",
    "for fq in frequency_variation:\n",
    "    train_features=extract_features(train_data,fq)\n",
    "    valid_features=extract_features(valid_data,fq)\n",
    "    test_features=extract_features(test_data,fq)\n",
    "\n",
    "    train_labels=train_labels.reshape((train_labels.shape[0],1))\n",
    "    valid_labels=valid_labels.reshape((valid_labels.shape[0],1))\n",
    "    test_labels=test_labels.reshape((test_labels.shape[0],1))\n",
    "    classifier=train(train_features,train_labels,valid_features,valid_labels,hid_neuron,verb=0,epochs=100)\n",
    "    test_out=classifier.predict(test_features)\n",
    "    test_predict=test_out>0.5\n",
    "    accuracy=(test_predict==test_labels).sum()/20.0\n",
    "    print(fq,accuracy)\n",
    "    Accuracy_freq.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    0.45]\n",
      " [ 2.    0.55]\n",
      " [ 3.    0.8 ]\n",
      " [ 4.    0.8 ]\n",
      " [ 5.    0.85]\n",
      " [ 6.    0.85]\n",
      " [ 7.    0.8 ]\n",
      " [ 8.    0.8 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.vstack([frequency_variation, Accuracy_freq]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After this use matplotlib to plot accuracy vs frequency curve and Accuracy vs neuron_variation curve :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Frequency VS Accuracy')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8VfWd//HXm7CETfZ9MYCsIosEXKitDqK4gR07LbZWUattx632Z612tHW0Oq1Tu00dK1rcFa0dJSgVcN81QQPKvoiQhCXsOyHJ5/fHObTXmOReICcnN/k8H4/z4J79k5twP/d8v+d8PzIznHPOueo0ijsA55xzdZ8nC+ecc0l5snDOOZeUJwvnnHNJebJwzjmXlCcL55xzSXmycM45l5QnC1ejJK2WtFfSroSpe9xx1TZJSyRdVsny6yTlha+PlTRH0lZJ2yTNk3R2kuOeKskk3RhV7M5VxpOFi8J5ZtYqYSqquIGkxnEEVoseAS6uZPl3w3UAM4G5QBegM3AtsCPJcS8BtoT/1qoG8Dtz1fBk4WqFpKzwG/HlktYAr4bLT5T0bvjNer6kUxP26SPpDUk7Jc2V9CdJj4frTpVUUOEcqyWdHr5uJOkmSSslbZb0jKT2FWK5RNIaSZsk/UfCcTIk/Szcd2f4jb+XpHsl3VPhnDMl/aiSH/kx4CuSjk7YdjAwDHhKUkegD/CAmZWE0ztm9nY172EL4BvAVUB/SdkV1n8l4b1cK2lKuLy5pHskfS5pu6S3w2XJ3sPbJD0r6XFJO4ApksZIei88x7rwd9I0Yf9jw9/VFkkbwvexq6Q9kjokbDdKUrGkJlX9vK5u8WThatvXgMHAmZJ6AC8CvwTaAzcAf5PUKdz2SWAe0BG4g0P7Nn0tcH54vu7AVuDeCtt8BRgIjAN+Hn6YA/wYuBA4GzgKuAzYQ3BFcKGkRgDhB/444KmKJzezAuA1giuJgy4GZpnZJmAzsAJ4XNL5krqk8DNdAOwC/grMJuHKRVJv4O/A/wCdgBFAfrj6N8Ao4GSC9/lGoDyF8wFMAp4F2gJPAGXA9QS/k5MIfv5/D2NoDbwMvETwnh8DvGJm64HXgW8mHPciYLqZHUgxDhc3M/PJpxqbgNUEH2jbwun5cHkWYEDfhG1/CjxWYf/ZBEmhN1AKtExY9yTwePj6VKCgknOfHr5eDIxLWNcNOAA0ToilZ8L6D4HJ4eulwKQqfr7FwPjw9dUEH/5VvRcXAUvD142ANcDXE9b3BP4ErCT48H4T6F/N8V4Gfh++vhAoBpqE8zcDz1WyTyNgLzC8knXJ3sPbgDeT/L5/dPC8YUwfV7Hdt4B3wtcZwHpgTNx/rz6lPvmVhYvC+WbWNpzOr7BubcLro4F/C5s0tknaRvBtvxvh1YCZ7U7Y/vNDiOFo4LmE4y4m+Fac+A1+fcLrPUCr8HUvgg/wyjxCkAQI/32smhj+D+gm6USCD+YWBFdSQHD1YWZXm1m/MN7dwKOVHUhSL+A0gm/3ADOATOCcJDF3DLer6udJJvH3haQBkl6QtD5smrorPEd1MRyMd4ikvsB4YLuZfXiYMbkYeLJwtS1xmOO1BFcWbROmlmb2K2Ad0E5Sy4Tteye83k3w4QsE/QwEzS+Jxz6rwrEzzawwhRjXAv2qWPc4MEnScILmtOer/EHN9hA04VxM0Bw13cxKqth2LUEz2dAqDvddgv+vMyWtB1YRJIGDTVFVxbwJ2FfFumTvIXzx9wVwH7CE4AroKOBngJLEgJntA54BvhP+LNUlWVcHebJwcXocOE/SmWGncmbY6drTzD4H8oD/lNRU0leA8xL2XQZkSjon7CS9BWiWsP7PwJ0HO5gldZI0KcW4HgTukNRfgWEHO2ct6IvIJfiw+5uZ7U1yrEcImmAu4J93QSGpnaT/lHRM2BnfkaBv5P0qjnMx8J8EfREHpwuAc8LYngBOl/RNSY0ldZA0wszKgWnAbyV1D9/nkyQ1I/l7WJnWBHds7ZI0CPhhwroXgK6SfiSpmaTWkk5IWP8oMAWYSPC7d2nEk4WLTfhtehLBt9Nigm+mP+Gff5ffBk4guFX0FyQ00ZjZdoKO1QeBQoJvyYl39vwByAHmSNpJ8CGc+MFVnd8SfAueQ/DB+BegecL6R4DjSO3b8ZvAdqDQzHITlpcQ9J28HJ7jU2A/wYfpF4TNWFnAvWa2PmHKIegkv9DM1hB0yP8/gvcrHxgeHuIG4BOCJLcF+DXQKIX3sDI3EPxedgIPAE8fXGFmOwmamM4jaOJbTtB0dnD9OwR9Mx+Z2eok53F1jMy8+JFLD5JuA44xs4uSbRtxHF8l+GacFX5zdymS9CrwpJk9GHcs7tD4QzbOHYKwueY64EFPFIdG0mjgeIKrSZdmvBnKuRSFz2FsI7hb6/cxh5NWJD1C0OT2o7C5yqUZb4ZyzjmXlF9ZOOecS6re9Fl07NjRsrKy4g7DOefSyrx58zaZWcXna76k3iSLrKws8vLy4g7DOefSiqSURkbwZijnnHNJebJwzjmXlCcL55xzSXmycM45l5QnC+ecc0lFmiwkTZC0VNIKSTdVsr63pNckfSxpgcJi9QrKXu6VlB9Of44yTuecc9WL7NbZcGz8ewlGoSwAciXlmNmihM1uAZ4xs/skDQFmEYyuCbDSzEZEFZ9zzrnURfmcxRhghZmtApA0nWAAscRkYQQ1jgHaAEURxuNcvbF1dwnP5K1l9/7SuENJWb/OrThvWHcaNVLyjV2dE2Wy6MEXSzIW8OV6ArcR1Bu4BmgJnJ6wro+kjwnG+r/FzN6qeAJJVwJXAvTu3bviaufqnZLSch57/3P+8PIyduwrRWnyuXtwCLoH3lrFrecM4YS+HeINyB2yKJNFZX/GFUctvBB42MzukXQS8JikoQQlNXub2WZJo4DnJR1rZju+cDCzqcBUgOzsbB8R0dVbZsYrizdy56zFfLZpN6f078gt5wxhYNfWcYeWEjMjZ34Rv/77Er419X3OGtqVm88aTO8OLZLv7OqEKJNFAUEB94N68uVmpsuBCQBm9p6kTKCjmW0kqBqGmc2TtBIYQFBm07kGZfG6HfzyxUW8s2IzfTu1ZNqUbE4b2Bmly2UFIIlJI3pwxpCuPPDWKu57fSWvLN7IpWOzuOpfjuGozCZxh+iSiDJZ5AL9JfUhKNk4maAcY6I1wDjg4bBWQCZQLKkTsMXMyiT1BfoTFKh3rsHYtGs/98xZxtO5a2id2YTbzhvCd048miYZ6XvHe/OmGVw7rj/fGt2Lu19ayv1vruLZeQX8+IwBTB7dmwzvz6izIq1nEd4K+3sgA5hmZndKuh3IM7Oc8A6oB4BWBE1UN5rZHEkXALcDpUAZ8Aszm1ndubKzs80HEnT1wf7SMh5+ZzV/enUFew+UcdGJR/Oj0/vTtkXTuEOrcQsKtnHHC4vIXb2VQV1bc+u5Qxh7TMe4w2pQJM0zs+yk29WX4keeLFy6MzNe+nQ9//X3JazZsodxgzrzs3MG069Tq7hDi5SZ8fdP13PXrMUUbN3L6YM787OzB9O3nv/cdYUnC+fSyKeF27n9hUV8+NkWBnZpzS3nDuaU/klLDNQr+w6U8dA7q7n3tRXsO1DGxSdlcd24/rRp4f0ZUfJk4Vwa2LhjH/89eynPflRAuxZN+fH4AUwe3YvGadwvcaSKd+7nt3OXMj13LW2aN+H60wfw7RN6p3VfTV3mycK5OmzfgTIefGsV//v6Sg6UlXPp2D5cddoxtGnu36IPWlQU3AX27srN9OvUklvOHcJpAzvHHVa948nCuTrIzJi5YB2//vsSCrft5cxju3DzWYPJ6tgy7tDqJDPj5cUbufPFRazevIevDujELecMZkCX9Hi+JB14snCujvl4zVbueGERH63ZxpBuR3HruUM4qZ8/yZyKktJyHn1vNX94ZTl7Ssr49pjeXD9+AO1b1r87xGqbJwvn6oiibXu5+6UlPJ9fRMdWzfjJmQP4xqhe/kzBYdiyu4TfzV3Gkx+uoUXTDK4b15+LT8qiaWPvzzhcniyci9meklL+/MYqpr65knKDK07pww9PPYZWzaJ8FrZhWL5hJ3e8uJg3lxWT1aEFPzt7MOOHdEmrp9rrCk8WzsWkvNx47uNC7p69hA079nPusG78dMIgerX3cZBq2mtLN3Lni4tZsXEXJ/frwC3nDGFI96OS7+j+wZOFczHIW72F219YxIKC7Qzv2YZbzx1Cdlb7uMOq1w6UlfPkB2v43cvL2L73AJNH9+LH4wfSqXWzuENLC54snKtFa7fs4VcvLeHFBevoelQmN04YyPkjenjthlq0fc8B/vDKch59bzWZTTK46rRjuHRsFplNMuIOrU7zZOFcLdi1v5T/fW0FD779GY0E3/9qP77/tb60aOr9EnFZVbyLu2Yt5uXFG+nVvjk3nzWYs4Z29f6MKniycC5CZeXGs/PW8t+zl7Fp136+PrIHN04YSLc2zeMOzYXeXr6JX764iCXrdzImqz23njuE43q2iTusOseThXMReXflJn75wmIWrdvB8b3b8vPzjmVEr7Zxh+UqUVZuPJ27lnvmLGXLnhL+dWRPbpwwkC5HZcYdWp3hycK5GrZ6027umrWYOYs20KNtc246axDnDuvmzRtpYMe+A9z72goeens1GY3ED0/txxWn9KV5U+/P8GThXA3ZvvcAf3p1OQ+/u5omGY246rRjuPwrfbzjNA2t2byH//r7Yv7+6Xq6t8nkp2cNYuLw7g064XuycO4IlZaV81TuWn43dxlb95Twb6N6csMZA+nsTRhp7/1Vm7njhUUsLNrByN5tufXcIRzfu13cYcUi1WQR6TPykiZIWipphaSbKlnfW9Jrkj6WtCCsrHdw3c3hfkslnRllnM5V9OayYs7+41vc+vyn9O/ciplXf4W7vzHcE0U9cWLfDuRc/RXu/sYwCrbu5V//912um/4xhdv2xh1anRXZlYWkDGAZMB4oIKjJfaGZLUrYZirwsZndF5ZYnWVmWeHrp4AxQHfgZWCAmZVVdT6/snA1YcXG4LbLV5dspHf7Fvzs7EGceazfdlmf7d5fyn2vr+SBt1YB8P2v9uX7X+tHywYyLEuqVxZRvhtjgBVmtioMaDowCViUsI0BB5/NbwMUha8nAdPNbD/wmaQV4fHeizBeV8P2lJTyg8c/YuvukrhDSYlhLFm3k+ZNMrj5rEFMGZtFs8beL1HftWzWmBvOHMjkMb349UtL+eOrK3jigzV0b5s+t0EP6NKae745PNJzRJksegBrE+YLgBMqbHMbMEfSNUBL4PSEfd+vsG+PiieQdCVwJUDv3r1rJGhXc2YvXM+by4o5uV+HtOkMHpPVgX8/rR8dW/lQEQ1Nz3Yt+J8LRzLl5CymvfMZe0uqbMioc9rVQunZKJNFZdftFdu8LgQeNrN7JJ0EPCZpaIr7YmZTgakQNEMdYbyuhs3IL6JH2+Y8fvkJPuyFSxujjm7HqKMbZmd3daLs4C4AeiXM9+SfzUwHXQ48A2Bm7wGZQMcU93V12KZd+3lr+SYmjujuicK5eiDKZJEL9JfUR1JTYDKQU2GbNcA4AEmDCZJFcbjdZEnNJPUB+gMfRhirq2GzPllHWbkxaUT3uENxztWAyJqhzKxU0tXAbCADmGZmCyXdDuSZWQ7w/4AHJF1P0Mw0xYLbsxZKeoagM7wUuKq6O6Fc3TMjv4hBXVszqKvXFnCuPoj03jAzmwXMqrDs5wmvFwFjq9j3TuDOKONz0Vi7ZQ/zPt/KjRMGxh2Kc66GeOFaV+Ny5gfdS+cN8yYo5+oLTxauxuXkF5F9dDsvI+pcPeLJwtWoJet3sHTDTu/Ydq6e8WThatSM/CIyGomzj+sWdyjOuRrkycLVmPJyIye/iFP6d6SDPwHtXL3iycLVmI/WbKVw215vgnKuHvJk4WrM8/mFZDZpxPghXeMOxTlXwzxZuBpxoKycFxes4/TBXWjVQIZ2dq4h8WThasTbyzexdc8Bzh/xpcGBnXP1gCcLVyNm5BfSpnkTvjqgU9yhOOci4MnCHbE9JaXMWbSBs4/rRtPG/iflXH3k/7PdEXt58Ub2lJT5XVDO1WOeLNwRy8kvpOtRmYzJah93KM65iHiycEdk6+4SXl9a7EWOnKvnPFm4I/L3T9dTWm5MHO5NUM7VZ54s3BGZkV9Iv04tOba7Fzlyrj6LNFlImiBpqaQVkm6qZP3vJOWH0zJJ2xLWlSWsq1iO1dUBRdv28sFnW5g0ogeSN0E5V59F9qitpAzgXmA8UADkSsoJq+MBYGbXJ2x/DTAy4RB7zWxEVPG5IzczLHLkTVDO1X9RXlmMAVaY2SozKwGmA5Oq2f5C4KkI43E1bEZ+ESN6tSWrY8u4Q3HORSzKZNEDWJswXxAu+xJJRwN9gFcTFmdKypP0vqTzq9jvynCbvOLi4pqK26Vg+YadLFq3w5+tcK6BiDJZVNaIbVVsOxl41szKEpb1NrNs4NvA7yX1+9LBzKaaWbaZZXfq5MNM1Kac+UU0EpwzzIscOdcQRJksCoBeCfM9gaIqtp1MhSYoMysK/10FvM4X+zNcjMyMGflFjD2mI51bZ8YdjnOuFkSZLHKB/pL6SGpKkBC+dFeTpIFAO+C9hGXtJDULX3cExgKLKu7r4pG/dhtrtuzxjm3nGpDI7oYys1JJVwOzgQxgmpktlHQ7kGdmBxPHhcB0M0tsohoM3C+pnCCh/SrxLioXrxn5RTRt3Igzh3qRI+caikir1JjZLGBWhWU/rzB/WyX7vQscF2Vs7vCUlpXzwoJ1jBvUmaMym8QdjnOulvgT3O6QvLdqM5t27fe7oJxrYDxZuEMyI7+I1s0ac+rAznGH4pyrRZ4sXMr2HSjjpU/XM2FoVzKbZMQdjnOuFnmycCl7dclGdu0v5fyRXmfbuYbGk4VL2Yz8Qjq1bsaJfTvEHYpzrpZ5snAp2b73AK8tKea8Yd3J8CJHzjU4nixcSmZ/up6SsnK/C8q5BsqThUvJjPmFZHVowbCebeIOxTkXA08WLqmNO/bx7srNTPQiR841WJ4sXFIzF6zDzIscOdeQebJwSeXkFzK0x1Ec07lV3KE452LiycJV67NNu5lfsJ1Jw/3ZCucaMk8Wrloz8guR4NzhXuTIuYbMk4WrkpmRk1/ECX3a061N87jDcc7FyJOFq9KnhTtYtWk354/wJijnGrpIk4WkCZKWSloh6aZK1v9OUn44LZO0LWHdJZKWh9MlUcbpKjcjv5AmGeKsod4E5VxDF1nxI0kZwL3AeIJ63LmSchIr3pnZ9QnbX0NYZ1tSe+AXQDZgwLxw361Rxeu+qKzcmLmgiFMHdqZNCy9y5FxDF+WVxRhghZmtMrMSYDowqZrtLwSeCl+fCcw1sy1hgpgLTIgwVlfBB59tZsMOL3LknAtEmSx6AGsT5gvCZV8i6WigD/Dqoewr6UpJeZLyiouLayRoF8jJL6Jl0wzGDeoSdyjOuTogymRR2bgQVsW2k4FnzazsUPY1s6lmlm1m2Z06dTrMMF1F+0vLmPXJOs48tivNm3qRI+dctMmiAOiVMN8TKKpi28n8swnqUPd1NeyNpcXs2FfKRG+Ccs6FokwWuUB/SX0kNSVICDkVN5I0EGgHvJeweDZwhqR2ktoBZ4TLXC2YMb+IDi2bMvaYjnGH4pyrIyJLFmZWClxN8CG/GHjGzBZKul3SxIRNLwSmm5kl7LsFuIMg4eQCt4fLXMR27jvAy4s2cM6wbjTJ8MdwnHOBpLfOSroaeOJwbls1s1nArArLfl5h/rYq9p0GTDvUc7ojM2fhBvaXepEj59wXpfLVsSvBMxLPhA/ZeUGDemzG/CJ6tmvO8b3bxR2Kc64OSZoszOwWoD/wF2AKsFzSXZL6RRybq2XFO/fzzopNTBrR3YscOee+IKVG6bA/YX04lRJ0SD8r6e4IY3O1bNYn6ygrNyb5WFDOuQpS6bO4FrgE2AQ8CPzEzA5IagQsB26MNkRXW2bkFzKoa2sGdGkddyjOuTomlbGhOgL/amafJy40s3JJ50YTlqttazbv4aM12/jphEFxh+Kcq4NSaYaaBfzjtlVJrSWdAGBmi6MKzNWumQuCZx7P8yJHzrlKpJIs7gN2JczvDpe5esLMeP7jQkZntaNnuxZxh+Ocq4NSSRaq8MBcOREObe5q35L1O1m+cRcTvWPbOVeFVJLFKknXSmoSTtcBq6IOzNWe5/MLadxInHOcN0E55yqXSrL4AXAyUEgwwN8JwJVRBuVqT3m5MTO/iFP6d6R9y6Zxh+Ocq6OSNieZ2UaCQQBdPZT3+VaKtu/jp2f5XVDOuaql8pxFJnA5cCyQeXC5mV0WYVyulszIL6R5kwxOH+xFjpxzVUulGeoxgvGhzgTeIKgtsTPKoFztKCkt58VP1jF+SBdaNvN7FpxzVUslWRxjZrcCu83sEeAc4Lhow3K14e0VxWzbc8BHmHXOJZVKsjgQ/rtN0lCgDZAVWUSu1szIL6Jtiyac0t9L0jrnqpdK28PUsFrdLQSV7loBt0YalYvcnpJS5izcwNeP70HTxl7kyDlXvWo/JcLBAneY2VYze9PM+ppZZzO7P5WDh/UvlkpaIemmKrb5pqRFkhZKejJheZmk/HD6UjlWd2TmLtrA3gNlTBruTVDOueSqvbIIBwu8GnjmUA8sKQO4FxhP8HxGrqQcM1uUsE1/4GZgrJltldQ54RB7zWzEoZ7XpSYnv4hubTIZndU+7lCcc2kglfaHuZJukNRLUvuDUwr7jQFWmNkqMysBpgOTKmxzBXDvwZKt4TMdLmJbd5fwxrJiJg7vTqNGXuTIOZdcKn0WB5+nuCphmQF9k+zXA1ibMH/w6e9EAwAkvQNkALeZ2UvhukxJeQTFln5lZs9XPIGkKwmfJu/du3fyn8QB8OIn6ygtNyb6XVDOuRSl8gR3n8M8dmVfWa3CfGOCkq2nEjy/8ZakoWa2DehtZkWS+gKvSvrEzFZWiG0qMBUgOzu74rFdFXLyi+jfuRVDuh0VdyjOuTSRyhPcF1e23MweTbJrAdArYb4nUFTJNu+b2QHgM0lLCZJHrpkVhedZJel1YCSwEndECrft5cPVW7jhjAFeZ9s5l7JU+ixGJ0ynALcBE1PYLxfoL6mPpKYE40tVvKvpeeA0AEkdCZqlVklqJ6lZwvKxwCLcEZs5P8jXE4f7cOTOudSl0gx1TeK8pDYEQ4Ak2680vJNqNkF/xDQzWyjpdiDPzHLCdWdIWgSUEdT33izpZOB+SeUECe1XiXdRucM3I7+Ikb3b0ruDFzlyzqXucAYE2kPQVJSUmc0iKMuauOznCa8N+HE4JW7zLj6kSI1btmEni9ft4LbzhsQdinMuzaTSZzGTf3ZMNwKGcBjPXbj45eQX0UhwzjC/C8o5d2hSubL4TcLrUuBzMyuIKB4XETNjxvxCxh7TkU6tm8UdjnMuzaSSLNYA68xsH4Ck5pKyzGx1pJG5GvXx2m2s3bKX68YNiDsU51waSuVuqL8C5QnzZeEyl0Zy8oto2rgRZx7rRY6cc4culWTROByuA4DwtRdrTiOlZeW8sKCI0wd3pnVmk7jDcc6loVSSRbGkfzxXIWkSsCm6kFxNe2flZjbtKmHSCH+2wjl3eFLps/gB8ISkP4XzBUClT3W7umlGfiGtMxtz6kAvcuScOzypPJS3EjhRUitAZub1t9PIvgNlzP50PecO606zxhlxh+OcS1NJm6Ek3SWprZntMrOd4VAcv6yN4NyRe2XxRnaXlHmdbefcEUmlz+KscBRYAMLaE2dHF5KrSTPyC+ncuhkn9O0QdyjOuTSWSrLIODioHwTPWQD+VFca2L7nAK8vLea84d3J8CJHzrkjkEoH9+PAK5IeCucvBR6JLiRXU15auI6SsnJvgnLOHbFUOrjvlrQAOJ2goNFLwNFRB+aO3Iz8Ivp0bMlxPdrEHYpzLs2l0gwFsJ7gKe4LgHHA4sgicjViw459vLdqMxOHd/ciR865I1bllYWkAQQFiy4ENgNPE9w6e1otxeaOwMz5RZjhTVDOuRpRXTPUEuAt4DwzWwEg6fpaicodsRn5RQzr2Ya+nVrFHYpzrh6orhnqAoLmp9ckPSBpHEGfRcokTZC0VNIKSTdVsc03JS2StFDSkwnLL5G0PJwuOZTzNnQri3fxSeF2Jg73qwrnXM2o8srCzJ4DnpPUEjgfuB7oIuk+4Dkzm1PdgSVlAPcC4wmGCMmVlJNYHlVSf+BmYKyZbZXUOVzeHvgFkE1QeGleuO/WI/hZG4yc/CIkOM+ThXOuhiTt4Daz3Wb2hJmdC/QE8oFKrxIqGAOsMLNV4Ui104FJFba5Arj3YBIws43h8jOBuWa2JVw3F5iQ0k/UwJkZOfOLOKlvB7oclRl3OM65eiLVu6EACD+87zezf0lh8x7A2oT5gnBZogHAAEnvSHpf0oRD2BdJV0rKk5RXXFyc+g9Sj31SuJ3PNu32jm3nXI06pGRxiCrr37AK842B/sCpBHddPSipbYr7YmZTzSzbzLI7dfIRVSHo2G6a0YgJx3aLOxTnXD0SZbIoAHolzPcEiirZZoaZHTCzz4ClBMkjlX1dBWXlxsz5RZw6sBNtWniRI+dczYkyWeQC/SX1kdSU4JmNnArbPA+cBiCpI0Gz1CpgNnBGOMJtO+CMcJmrxgerNrNx534vcuScq3GpjA11WMysVNLVBB/yGcA0M1so6XYgz8xy+GdSWERQ2/snZrYZQNIdBAkH4HYz2xJVrPXFjPwiWjbNYNzgznGH4pyrZyJLFgBmNguYVWHZzxNeG/DjcKq47zRgWpTx1Sf7DpQx69N1nDm0K5lNvMiRc65mRdkM5WrR60uL2bmvlPO9Cco5FwFPFvVEzvxCOrZqysn9vMiRc67mebKoB3buO8DLizdy7rDuNM7wX6lzrub5J0s9MHvhBkpKy5noD+I55yLiyaIemJFfSK/2zRnZq23coTjn6ilPFmmueOd+3lmxiUnDe3iRI+dcZDxZpLkXFxRR7kWOnHMR82SR5mbML2Jwt6Po36V13KE45+oxTxZpbM3mPXy8ZptfVTjnIufJIo3NyC8EvMiRcy56nizSlJnxfH4hY7La06Nt87hes4MaAAAP60lEQVTDcc7Vc54s0tSidTtYWbybSSP9qsI5Fz1PFmkqJ7+Ixo3E2UO9yJFzLnqeLNJQeXlQZ/trAzrRrmXTuMNxzjUAnizSUO7qLazbvs+H93DO1ZpIk4WkCZKWSloh6aZK1k+RVCwpP5y+l7CuLGF5xQp7DdqM+UU0b5LB+CFd4g7FOddARFb8SFIGcC8wnqCmdq6kHDNbVGHTp83s6koOsdfMRkQVX7oqKS1n1ifrOOPYLrRoGmntKuec+4coryzGACvMbJWZlQDTgUkRnq9BeGt5Mdv2HPAH8ZxztSrKZNEDWJswXxAuq+gCSQskPSupV8LyTEl5kt6XdH5lJ5B0ZbhNXnFxcQ2GXjft2l/KPXOW0b5lU07p3ynucJxzDUiUyaKyIVCtwvxMIMvMhgEvA48krOttZtnAt4HfS+r3pYOZTTWzbDPL7tSpfn94Higr59+f+IilG3by228Op4kXOXLO1aIoP3EKgMQrhZ5AUeIGZrbZzPaHsw8AoxLWFYX/rgJeB0ZGGGudZmb8x3Of8OayYu76+lBOHdg57pCccw1MlMkiF+gvqY+kpsBk4At3NUlKfKJsIrA4XN5OUrPwdUdgLFCxY7zB+MMry3kmr4Brx/XnW6N7xx2Oc64Biux2GjMrlXQ1MBvIAKaZ2UJJtwN5ZpYDXCtpIlAKbAGmhLsPBu6XVE6Q0H5VyV1UDcIzeWv5/cvL+caonlx/ev+4w3HONVAyq9iNkJ6ys7MtLy8v7jBq1JvLirns4VxO6teBaVNGez+Fc67GSZoX9g9Xyz996qiFRdv54ePz6N+lNf/7neM9UTjnYuWfQHVQ4ba9XPpQLm2aN+HhS0fTOrNJ3CE55xo4fwS4jtm+5wBTpn3I3gNl/O2HJ9PlqMy4Q3LOOb+yqEv2l5Zx5WN5rN68m/u/O4oBXlfbOVdH+JVFHVFebtzw1wV88NkW/jB5BCf36xh3SM459w9+ZVFH/Hr2EmbOL+KnEwYxaURlo6I451x8PFnUAY++t5r731jFRSf25gdf6xt3OM459yWeLGI2d9EGbstZyOmDO3PbecciVTaklnPOxcuTRYw+XrOVa576iON6tOGPF46ksT9L4Zyro/zTKSarN+3m8kfy6Nw6k79MGe2FjJxzdZonixhs3rWfKQ99iJnxyGVj6NiqWdwhOedctfzrbC3bW1LG9x7NY932fTx5xYn06dgy7pCccy4pTxa1qKzcuG76x+Sv3cZ93xnFqKPbxR2Sc86lxJuhaomZcfvMhcxZtIFfnDuECUO7xh2Sc86lzJNFLXngrVU88t7nXHFKH6aM7RN3OM45d0g8WdSCmfOLuGvWEs4Z1o2bzxocdzjOOXfIIk0WkiZIWipphaSbKlk/RVKxpPxw+l7CukskLQ+nS6KMM0ofrNrM/3tmPmOy2nPPvw2nUSN/6M45l34i6+CWlAHcC4wHCoBcSTmVlEd92syurrBve+AXQDZgwLxw361RxRuF5Rt2csWjefRq35ypF48is0lG3CE559xhifLKYgywwsxWmVkJMB2YlOK+ZwJzzWxLmCDmAhMiijMSG3fsY8pDuTRrksHDl46hbYumcYfknHOHLcpk0QNYmzBfEC6r6AJJCyQ9K6nXoewr6UpJeZLyiouLayruI7ZrfymXPpzL1j0lPDRlNL3at4g7JOecOyJRJovKGuetwvxMIMvMhgEvA48cwr6Y2VQzyzaz7E6dOh1RsDXlQFk5Vz3xEUvW7+Te7xzP0B5t4g7JOeeOWJTJogDolTDfEyhK3MDMNpvZ/nD2AWBUqvvWRWbGLc99yhvLirnz/KGcNrBz3CE551yNiDJZ5AL9JfWR1BSYDOQkbiCpW8LsRGBx+Ho2cIakdpLaAWeEy+q0P76ygqfz1nLtvxzD5DG94w7HOedqTGR3Q5lZqaSrCT7kM4BpZrZQ0u1AnpnlANdKmgiUAluAKeG+WyTdQZBwAG43sy1RxVoT/pq3lt+9vIwLju/J9eMHxB2Oc87VKJl9qSsgLWVnZ1teXl4s535zWTGXPZzLiX07MG3KaJo29mcdnXPpQdI8M8tOtp1/qh2hhUXb+fcnPuKYzq2476LjPVE45+ol/2Q7AoXb9nLpQ7m0zmzMw5eOoXVmk7hDcs65SPgQ5Ydp+94DXPrQh+w9UMazPziZrm0y4w7JOeci41cWh2F/aRnffyyPzzbt5v7vjmJg19Zxh+Scc5HyK4tDVF5u/OSvC3h/1RZ+/60RnNyvY9whOedc5PzK4hDdPXspOfOLuHHCQM4fWdnoJc45V/94sjgEj73/OX9+YyUXndibH36tX9zhOOdcrfFkkaK5izbwixmfMm5QZ24771gkr0vhnGs4PFmkIH/tNq556iOO69GG//n2SBpn+NvmnGtY/FMvic837+byh3Pp1LoZD14ymhZN/Z4A51zD48miGlt2lzDloVzKzXjk0jF0at0s7pCccy4W/jW5CvsOlPG9R3Ip2raXJ684gb6dWsUdknPOxcaTRSXKyo3rpn/Mx2u3cd93jmfU0e3jDsk552LlzVAVmBl3vLCI2Qs3cOs5Q5gwtFvynZxzrp7zZFHBg299xsPvruZ7X+nDZV/pE3c4zjlXJ3iySPDCgiLunLWYc47rxs/OHhx3OM45V2dEmiwkTZC0VNIKSTdVs903JJmk7HA+S9JeSfnh9Oco4wT4YNVmfvz0fEZnteOebw6nUSN/6M455w6KrINbUgZwLzAeKAByJeWY2aIK27UGrgU+qHCIlWY2Iqr4Eq3YuJMrHs2jZ/vmPHBxNplNMmrjtM45lzaivLIYA6wws1VmVgJMByZVst0dwN3AvghjqdLGnfu4ZFouTRtn8MilY2jbomkcYTjnXJ0WZbLoAaxNmC8Il/2DpJFALzN7oZL9+0j6WNIbkk6p7ASSrpSUJymvuLj4sIJs1jiDQV1b89CU0fRq3+KwjuGcc/VdlM9ZVNbob/9YKTUCfgdMqWS7dUBvM9ssaRTwvKRjzWzHFw5mNhWYCpCdnW2VHCepNs2b8Jcpow9nV+ecazCivLIoAHolzPcEihLmWwNDgdclrQZOBHIkZZvZfjPbDGBm84CVwIAIY3XOOVeNKJNFLtBfUh9JTYHJQM7BlWa23cw6mlmWmWUB7wMTzSxPUqewgxxJfYH+wKoIY3XOOVeNyJqhzKxU0tXAbCADmGZmCyXdDuSZWU41u38VuF1SKVAG/MDMtkQVq3POuerJ7LCa+uuc7Oxsy8vLizsM55xLK5LmmVl2su38CW7nnHNJebJwzjmXlCcL55xzSXmycM45l1S96eCWVAx8fgSH6AhsqqFwopZOsUJ6xZtOsUJ6xZtOsUJ6xXsksR5tZp2SbVRvksWRkpSXyh0BdUE6xQrpFW86xQrpFW86xQrpFW9txOrNUM4555LyZOGccy4pTxb/NDXuAA5BOsUK6RVvOsUK6RVvOsUK6RVv5LF6n4Vzzrmk/MrCOedcUp4snHPOJdXgk4WkaZI2Svo07liSkdRL0muSFktaKOm6uGOqiqRMSR9Kmh/G+p9xx5SMpIywOmNllRvrFEmrJX0iKV9SnR9BU1JbSc9KWhL+/Z4Ud0yVkTQwfE8PTjsk/SjuuKoj6frw/9inkp6SlBnJeRp6n4WkrwK7gEfNbGjc8VRHUjegm5l9JKk1MA8438wWxRzal0gS0NLMdklqArwNXGdm78ccWpUk/RjIBo4ys3Pjjqc6YcGwbDNLi4fGJD0CvGVmD4b1bVqY2ba446pOWFOnEDjBzI7kgd/ISOpB8H9riJntlfQMMMvMHq7pczX4KwszexNIi1oZZrbOzD4KX+8EFlOhrnldYYFd4WyTcKqz30wk9QTOAR6MO5b6RtJRBDVq/gJgZiV1PVGExgEr62qiSNAYaC6pMdCCL1YkrTENPlmkK0lZwEjgg3gjqVrYrJMPbATmmlmdjRX4PXAjUB53ICkyYI6keZKujDuYJPoCxcBDYTPfg5Jaxh1UCiYDT8UdRHXMrBD4DbAGWAdsN7M5UZzLk0UaktQK+BvwIzPbEXc8VTGzMjMbQVB/fYykOtnMJ+lcYGNY7z1djDWz44GzgKvC5tS6qjFwPHCfmY0EdgM3xRtS9cKmsonAX+OOpTqS2gGTgD5Ad6ClpIuiOJcnizQTtv//DXjCzP4v7nhSETY5vA5MiDmUqowFJob9ANOBf5H0eLwhVc/MisJ/NwLPAWPijahaBUBBwpXlswTJoy47C/jIzDbEHUgSpwOfmVmxmR0A/g84OYoTebJII2Gn8V+AxWb227jjqY6kTpLahq+bE/xRL4k3qsqZ2c1m1tPMsgiaHl41s0i+ndUESS3DGxwIm3POAOrs3Xxmth5YK2lguGgcUOduyqjgQup4E1RoDXCipBbh58M4gr7MGtfgk4Wkp4D3gIGSCiRdHndM1RgLfJfgm+/BW/vOjjuoKnQDXpO0AMgl6LOo87ekpokuwNuS5gMfAi+a2Usxx5TMNcAT4d/DCOCumOOpkqQWwHiCb+l1Wni19izwEfAJwWd6JEN/NPhbZ51zziXX4K8snHPOJefJwjnnXFKeLJxzziXlycI551xSniycc84l1TjuAJyLm6QygtsODzrfzFbHFI5zdZLfOusaPEm7zKxVNesbm1lpbcbkXF3jzVDOVULSFEl/lTQTmBMu+4mkXEkLEutzSPoPSUslvRzWE7ghXP66pOzwdcdwOJGDAyz+d8Kxvh8uPzXc52DdhyfCp3KRNFrSu2F9kA8ltZb0lqQRCXG8I2lYbb1HrmHxZijnguGd88PXn5nZ18PXJwHDzGyLpDOA/gRjMAnICQfv200wRMhIgv9PHxHUGanO5QSjg46W1Ax4R9LBkUJHAscSDDP9DjBW0ofA08C3zCw3HPJ7L8Fw6lOAH0kaADQzswVH9E44VwVPFs7B3nB03IrmmtnBWidnhNPH4XwrguTRGnjOzPYASMpJ4XxnAMMkfSOcbxMeqwT40MwKwmPlA1nAdmCdmeUCHBxpWNJfgVsl/QS4DHg41R/YuUPlycK5qu1OeC3gv8zs/sQNwpKbVXX8lfLPpt7EUpcCrjGz2RWOdSqwP2FRGcH/UVV2DjPbI2kuwRDV3ySo8udcJLzPwrnUzAYuC2uJIKmHpM7Am8DXJTUPR4I9L2Gf1cCo8PU3Khzrh+Fw80gakKQY0BKgu6TR4fatw6poEDRF/RHITbgKcq7G+ZWFcykwszmSBgPvhX3Ou4CLwnroTwP5wOfAWwm7/QZ4RtJ3gVcTlj9I0Lz0UdiBXQycX825SyR9C/ifcLj3vQRDvu8ys3mSdgAP1dCP6lyl/NZZ52qQpNsIPsR/U0vn605QWGqQmaVLSViXhrwZyrk0Jelighrs/+GJwkXNryycc84l5VcWzjnnkvJk4ZxzLilPFs4555LyZOGccy4pTxbOOeeS+v94fg1bLxTKeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5d663d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(frequency_variation,Accuracy_freq)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Frequency VS Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Number of Neurons VS Accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5eaf7d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neuron_variation, Accuracy_neuron)\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Number of Neurons VS Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
